<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-08-04T04:03:31+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">maea2 blog</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</subtitle><entry><title type="html">Generalized random forest を理解する</title><link href="http://localhost:4000/2020/07/19/generalized-random-forest.html" rel="alternate" type="text/html" title="Generalized random forest を理解する" /><published>2020-07-19T00:00:00+09:00</published><updated>2020-07-19T00:00:00+09:00</updated><id>http://localhost:4000/2020/07/19/generalized-random-forest</id><content type="html" xml:base="http://localhost:4000/2020/07/19/generalized-random-forest.html">&lt;h1 id=&quot;generalized-random-forest-とは&quot;&gt;Generalized random forest とは&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;セミパラメトリック推定にrandom forestを因果推論に利用した手法&lt;/li&gt;
  &lt;li&gt;heterogeneous treat ment effectを推定することができる。&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="github" /><summary type="html">Generalized random forest とは</summary></entry><entry><title type="html">Implicit Neural Representations with Periodic Activation Functions を読んだ</title><link href="http://localhost:4000/2020/06/20/SIREN.html" rel="alternate" type="text/html" title="Implicit Neural Representations with Periodic Activation Functions を読んだ" /><published>2020-06-20T00:00:00+09:00</published><updated>2020-06-20T00:00:00+09:00</updated><id>http://localhost:4000/2020/06/20/SIREN</id><content type="html" xml:base="http://localhost:4000/2020/06/20/SIREN.html">&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#どんな論文&quot; id=&quot;markdown-toc-どんな論文&quot;&gt;どんな論文？&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#参考動画&quot; id=&quot;markdown-toc-参考動画&quot;&gt;参考動画&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#implicit-problemとは&quot; id=&quot;markdown-toc-implicit-problemとは&quot;&gt;implicit problemとは？&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sirenの性質&quot; id=&quot;markdown-toc-sirenの性質&quot;&gt;SIRENの性質&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;どんな論文&quot;&gt;どんな論文？&lt;/h1&gt;

&lt;p&gt;高次の微分を含む陰関数方程式(implicit problem)を解く問題に対して活性化関数を$\sin$ 関数にしたNN(SIREN; sinusoidal representation network)を用いる手法を提案した。画像・動画・3D形状・音声など様々な領域の信号復元の問題がこの形式で定式化できて、各ドメインで信号復元の問題を解かせたところ、
既存のReLUなどを用いたNNに比べSNPR(Peak signale-to-noise ratio)が大幅に改善した。また、SIRENの適切な初期化条件についても理論・実験の両面から検証されている。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2006.09661&quot;&gt;論文リンク&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;参考動画&quot;&gt;参考動画&lt;/h2&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/Q2fLWGBeaiI&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h1 id=&quot;implicit-problemとは&quot;&gt;implicit problemとは？&lt;/h1&gt;

&lt;div class=&quot;definition&quot;&gt;
&lt;div class=&quot;box-title&quot;&gt;implicit problem&lt;/div&gt;
implicit problem とは 関数 $\Phi: \mathbb{R}^k \to\Omega$ で 
$$
F(\boldsymbol{x}, \Phi, \nabla_{\boldsymbol{x}}, \nabla_{\boldsymbol{x}}^2\Phi, ...) = 0
$$
を満たすような関数を探す問題のこと。$\Omega\subset \mathbb{R}^l$ は適当な閉領域 ($\Omega = \bigcup_{m=1}^{M} \Omega_m$ みたいな感じで分割されていても良い)
&lt;/div&gt;

&lt;h1 id=&quot;sirenの性質&quot;&gt;SIRENの性質&lt;/h1&gt;

&lt;div class=&quot;definition&quot;&gt;
&lt;div class=&quot;box-title&quot;&gt;SIREN&lt;/div&gt;

$$
\begin{align}
\mathrm{SIREN}_n(\boldsymbol{x}) &amp;amp; = \boldsymbol{W}_n(\phi_{n-1}\circ\phi_{n-2}\circ\cdots\circ\phi_0)(\boldsymbol{x})+\boldsymbol{b}_n \\
\phi_i &amp;amp; = \sin(\boldsymbol{W}_i\boldsymbol{x}+\boldsymbol{b}_i)  
\end{align}
$$

つまり、アフィン変換と周期関数(\sin)を交互に繰り返す構造。
&lt;/div&gt;

&lt;div class=&quot;theorem&quot;&gt;
&lt;div class=&quot;box-title&quot;&gt;SIRENの導関数はSIRENの積&lt;/div&gt;
$\sin^\prime(\theta)=\cos(\theta)=\sin(\theta+\pi/2)$が成り立つので、導関数を計算すると各要素はSIRENの積になる。
&lt;/div&gt;

&lt;p&gt;例えば、1次元かつ$n=2$のSIRENの導関数を考えると&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\mathrm{SIREN}_2(x) &amp; = w_2\sin(w_1\sin(w_0x+b_0)+b_1)+b_2\\
\frac{d}{dx}\mathrm{SIREN}_2(x) &amp; =  w_2\sin^\prime(w_1\sin(w_0x+b_0)+b_1)\sin^\prime(w_0x+b_0))w_0 \\
&amp; = w_2\sin(w_1\sin(w_0x+b_0)+b_1+\pi/2)\sin(w_0x+b_0+\pi/2)w_0 
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;となって、SIRENの積で評価できる。&lt;/p&gt;

&lt;p&gt;論文では$n=5$としているらしい。&lt;/p&gt;

&lt;p&gt;論文では各層で出力の分布が保たれるような初期化の方法についても議論していて、次の定理が成り立つ。&lt;/p&gt;

&lt;div class=&quot;theorem&quot;&gt;
&lt;div class=&quot;box-title&quot;&gt;SIRENの初期化条件について&lt;/div&gt;
各重み成分を$\boldsymbol{W}_{ij}$とするとき$\boldsymbol{W}_{ij}\overset{i.i.d.}{\sim} \mathcal{U}(-\sqrt{6/\text{前層の入力数}},\sqrt{6/\text{前層の入力数}})$とすると、各層(2層目以降)の中間層の出力が標準正規分布に従う。
&lt;/div&gt;

&lt;p&gt;この初期化の方法により、出力の分布が層数によらないようにしている。実験も行われており、たしかに分布が変化していないことがわかる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/siren_initialization.png&quot; alt=&quot;sirenの初期化&quot; /&gt;
&lt;strong&gt;6層のSIRENを上記の条件で初期化した場合の各層の分布とスペクトル。理論値と合致しており、スペクトルについても緩やかに変化していることが見て取れる。&lt;/strong&gt;&lt;/p&gt;</content><author><name></name></author><category term="math" /><category term="statistics" /><category term="machine-learning" /><summary type="html"></summary></entry><entry><title type="html">単位根検定について</title><link href="http://localhost:4000/2020/05/10/unit-root-test.html" rel="alternate" type="text/html" title="単位根検定について" /><published>2020-05-10T00:00:00+09:00</published><updated>2020-05-10T00:00:00+09:00</updated><id>http://localhost:4000/2020/05/10/unit-root-test</id><content type="html" xml:base="http://localhost:4000/2020/05/10/unit-root-test.html">&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#単位根検定とは&quot; id=&quot;markdown-toc-単位根検定とは&quot;&gt;単位根検定とは&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#単位根検定&quot; id=&quot;markdown-toc-単位根検定&quot;&gt;単位根検定&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#df検定dickey-fuller-test&quot; id=&quot;markdown-toc-df検定dickey-fuller-test&quot;&gt;DF検定(Dickey-Fuller Test)&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#df分布&quot; id=&quot;markdown-toc-df分布&quot;&gt;DF分布&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;単位根検定とは&quot;&gt;単位根検定とは&lt;/h1&gt;

&lt;p&gt;期待値と自己共分散が$t$によらず一定であるような場合、その確率過程は弱定常過程であるという。
定常過程は定義からその変化が時刻に依存することがないので、平均回帰的(平均に戻ろうとする性質)でありかつ
トレンド(時刻に依存した変化)を持ちません。
しかし、時系列データのなかには必ずしも定常過程ではかけないようなものも存在します。
例えば株価や為替レートなどがその例です。そのような時系列データをモデリングする手法の最も基本的なものとして単位根過程があります。
これは差分は定常過程であることを仮定する確率モデルです。&lt;/p&gt;

&lt;div class=&quot;definition&quot;&gt;
&lt;div class=&quot;box-title&quot;&gt;単位根過程&lt;/div&gt;
確率過程$\{y_t\}$がすべての$t$について

$$
\Delta y_t:=y_t-y_{t-1}
$$

が弱定常過程になっているとき、$\{y_t\}$は単位根過程であるという。
&lt;/div&gt;

&lt;h1 id=&quot;単位根検定&quot;&gt;単位根検定&lt;/h1&gt;

&lt;p&gt;考えている確率過程が単位根過程であるか定常過程であるかを検定したいことがある。単位根過程には平均回帰性がないので、たとえば一度大きな変動が起きるとそれはその影響は
ランダムネスで打ち消されることはなく残ってしまう。反対に定常過程であれば一度大きな変動があっても時間が経てば平均に戻っていくはずである。
したがって、考えている確率過程が定常的に振る舞っているのか、単位根過程であるのかを検定する手段の一つとして単位根検定がある。
単位根検定では考えている確率過程が少なくとも単位根過程であることを仮定する。(定常過程ならば単位根過程である)&lt;/p&gt;

&lt;h2 id=&quot;df検定dickey-fuller-test&quot;&gt;DF検定(Dickey-Fuller Test)&lt;/h2&gt;

&lt;p&gt;考えている時系列の期待値が0であるかやトレンドを持つかどうかによって単位根検定にもバリエーションがある。
ここでは考えている確率過程の平均が0でトレンドを持たない場合を考える。すなわち、&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
&amp;H_0: y_t=y_{t-1}+u_t\\
&amp;H_1: y_t=\rho y_{t-1}+u_t, |\rho|&lt;1 
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;$u_t$は平均0の確率過程である。これは$\rho$についての検定と見ることができて、$H_0:\rho=1, H_1:|\rho|&amp;lt;1$に対応している。&lt;/p&gt;

&lt;h3 id=&quot;df分布&quot;&gt;DF分布&lt;/h3&gt;

&lt;p&gt;$\rho$のOLS推定量を$\hat{\rho}$とすると、サンプルサイズが$T$である場合は$\rho=1$の元での漸近分布として&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tau_{\rho=1}=T(\hat{\rho}-1)\overset{d}{\to}\frac{\frac{1}{2}\left\{[W(1)]^2-1\right\}}{\int_{0}^1[W(r)]^2dr}&lt;/script&gt;

&lt;p&gt;が成立することが知られており($\overset{d}{to}$は分布収束)、この漸近分布をDF分布という。検定のときはDF分布の棄却点を設定し、
$\tau_{\rho=1}$が棄却点より小さい場合は$H_0$を棄却する。&lt;/p&gt;</content><author><name></name></author><category term="math" /><category term="statistics" /><summary type="html"></summary></entry><entry><title type="html">ニューラルネットのover-parameterizationについて最近の論文を読んだ。</title><link href="http://localhost:4000/2020/05/04/over-parameterization.html" rel="alternate" type="text/html" title="ニューラルネットのover-parameterizationについて最近の論文を読んだ。" /><published>2020-05-04T00:00:00+09:00</published><updated>2020-05-04T00:00:00+09:00</updated><id>http://localhost:4000/2020/05/04/over-parameterization</id><content type="html" xml:base="http://localhost:4000/2020/05/04/over-parameterization.html">&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#モチベーション&quot; id=&quot;markdown-toc-モチベーション&quot;&gt;モチベーション&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#2層の場合の結果&quot; id=&quot;markdown-toc-2層の場合の結果&quot;&gt;2層の場合の結果&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#1の論文の設定&quot; id=&quot;markdown-toc-1の論文の設定&quot;&gt;[1]の論文の設定&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#neural-tangent-kernel&quot; id=&quot;markdown-toc-neural-tangent-kernel&quot;&gt;Neural Tangent Kernel&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#1の論文のキモ&quot; id=&quot;markdown-toc-1の論文のキモ&quot;&gt;[1]の論文のキモ&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#1の論文の主張&quot; id=&quot;markdown-toc-1の論文の主張&quot;&gt;[1]の論文の主張&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2の論文の設定&quot; id=&quot;markdown-toc-2の論文の設定&quot;&gt;[2]の論文の設定&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2の論文のキモ&quot; id=&quot;markdown-toc-2の論文のキモ&quot;&gt;[2]の論文のキモ&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2の論文の主張&quot; id=&quot;markdown-toc-2の論文の主張&quot;&gt;[2]の論文の主張&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#多層の場合の結果&quot; id=&quot;markdown-toc-多層の場合の結果&quot;&gt;多層の場合の結果&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#参考文献&quot; id=&quot;markdown-toc-参考文献&quot;&gt;参考文献&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;モチベーション&quot;&gt;モチベーション&lt;/h1&gt;

&lt;p&gt;近年用いられるニューラルネットではデータ数に対してパラメータ数が非常に多い状況が多い。これは既存の学習理論の枠組みとは相反する。パラメータ数が非常に多いモデルのことをover-parameterized modelという。&lt;/p&gt;

&lt;h1 id=&quot;2層の場合の結果&quot;&gt;2層の場合の結果&lt;/h1&gt;

&lt;p&gt;[1]では2層のニューラルネットで二乗損失を用いた場合に十分にユニット数で$m$が大きければ、勾配法による学習によって損失を限りなく小さくできることを示している。&lt;/p&gt;

&lt;h2 id=&quot;1の論文の設定&quot;&gt;[1]の論文の設定&lt;/h2&gt;

&lt;p&gt;2層ニューラルネットは次式で定義される。ここで$\sigma$はReLUである。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(\boldsymbol{x};\boldsymbol{W},\boldsymbol{a})=\frac{1}{\sqrt{m}}\sum_{r=1}^ma_i\sigma(\boldsymbol{w}_r^\top\boldsymbol{x})&lt;/script&gt;

&lt;p&gt;次の二乗損失を最小化する。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(\boldsymbol{W}, \boldsymbol{a}) = \sum_{i=1}^n \frac{1}{2}\left(y_i-f(\boldsymbol{x}_i;\boldsymbol{W}, \boldsymbol{a})\right)^2&lt;/script&gt;

&lt;p&gt;学習は勾配法で行う。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol{W}(k+1) = \boldsymbol{W}(k)-\eta\frac{\partial L(\boldsymbol{W}(k), \boldsymbol{a})}{\partial\boldsymbol{W}(k)}&lt;/script&gt;

&lt;h2 id=&quot;neural-tangent-kernel&quot;&gt;Neural Tangent Kernel&lt;/h2&gt;

&lt;p&gt;いま、損失を$L(\boldsymbol{W},\boldsymbol{a})=\sum_{i=1}^n \ell_i(f_{\boldsymbol{W}}(\boldsymbol{x}_i);\boldsymbol{a})$で定めておく。$\boldsymbol{a}$は固定するのがポイントになっている。Neural Tangent Kernelは2層ニューラルネットの勾配流を考えると出てくる量
で解析の際に重要な役割を果たす。学習のステップ幅を限りなく小さくすると、次の勾配流の式がでてくる。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\mathrm{d}\boldsymbol{w}_r}{\mathrm{d}t}=-\nabla_{\boldsymbol{w}_r} L(\boldsymbol{W},\boldsymbol{a})&lt;/script&gt;

&lt;p&gt;ここで、&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\frac{\mathrm{d}\boldsymbol{w}_r}{\mathrm{d}t}&amp;=-\nabla_{\boldsymbol{w}_r} L(\boldsymbol{W},\boldsymbol{a})\\
&amp;=-\sum_{i=1}^n \nabla_{\boldsymbol{w}_r} \ell_i(f_{\boldsymbol{W}}(\boldsymbol{x}_i);\boldsymbol{a})\\
&amp;=-\sum_{i=1}^n \frac{\mathrm{d}\ell_i(f_{\boldsymbol{W}})}{\mathrm{d}f_{\boldsymbol{W}}}a_r\nabla_{\boldsymbol{w}_r}\sigma(\boldsymbol{w}_r^\top\boldsymbol{x}_i)\\

\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;したがって、&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\frac{\mathrm{d} f_{\boldsymbol{W}}(\boldsymbol{x})}{\mathrm{d}t}=&amp;\sum_{r=1}^m\nabla_{\boldsymbol{w}_r}^\top f_{\boldsymbol{W}}\frac{\mathrm{d}\boldsymbol{w}_r}{\mathrm{d}t}\\
=&amp;\sum_{r=1}^m\nabla_{\boldsymbol{w}_r}^\top f_{\boldsymbol{W}}\left(-\sum_{i=1}^n \frac{\mathrm{d}\ell_i(f_{\boldsymbol{W}})}{\mathrm{d}f_{\boldsymbol{W}}}\nabla_{\boldsymbol{w}_r}\sigma(\boldsymbol{w}_r^\top\boldsymbol{x}_i)\right)\\
=&amp;\sum_{r=1}^m\nabla_{\boldsymbol{w}_r}^\top f_{\boldsymbol{W}}(\boldsymbol{x})\left(-\sum_{i=1}^n \frac{\mathrm{d}\ell_i(f_{\boldsymbol{W}})}{\mathrm{d}f_{\boldsymbol{W}}}\nabla_{\boldsymbol{w}_r}\sigma(\boldsymbol{w}_r^\top\boldsymbol{x}_i)\right)\\
=&amp;\sum_{r=1}^ma_r\nabla_{\boldsymbol{w}_r}^\top\sigma(\boldsymbol{w}_r^\top\boldsymbol{x})\left(-\sum_{i=1}^n \frac{\mathrm{d}\ell_i(f_{\boldsymbol{W}})}{\mathrm{d}f_{\boldsymbol{W}}}\nabla_{w_r}\sigma(\boldsymbol{w}_r^\top\boldsymbol{x}_i)\right)\\
=&amp;-\sum_{i=1}^n\frac{\mathrm{d}\ell_i(f_{\boldsymbol{W}})}{\mathrm{d}f_{\boldsymbol{W}}}\underbrace{\sum_{r=1}^ma_r\nabla_{\boldsymbol{w}_r}^\top\sigma(\boldsymbol{w}_r^\top\boldsymbol{x}) \nabla_{w_r}\sigma(\boldsymbol{w}_r^\top\boldsymbol{x}_i)}_{=:k_{\boldsymbol{W}}(\boldsymbol{x},\boldsymbol{x}_i)}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;$k_{\boldsymbol{W}}$をNeural Tangent Kernelという。多層の場合も中間層の出力を考えれば同様の手順で求めることができるはず。&lt;/p&gt;

&lt;h2 id=&quot;1の論文のキモ&quot;&gt;[1]の論文のキモ&lt;/h2&gt;

&lt;p&gt;他の論文でも繰り返し出てくるが、次のGram matrix $\boldsymbol{H}^\infty$が非常に重要な役割を果たす。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol{H}^\infty_{i,j} = \mathbb{E}_{\boldsymbol{w}\sim\mathcal{N}(\boldsymbol{0},\boldsymbol{I})}\left[\boldsymbol{x}_i^\top\boldsymbol{x}_j\mathbb{I}_{\left\{\boldsymbol{w}^\top\boldsymbol{x}_i\geq 0\text{ and } \boldsymbol{w}^\top\boldsymbol{x}_j\geq 0\right\}}\right]&lt;/script&gt;

&lt;h2 id=&quot;1の論文の主張&quot;&gt;[1]の論文の主張&lt;/h2&gt;

&lt;div class=&quot;box&quot;&gt;

$\boldsymbol{w}_r\sim\mathcal{N}(\boldsymbol{0},\boldsymbol{I})$
, $a_r\sim\mathrm{unif}(0,1)$で初期化された2層ニューラルネットはユニット数を$m=\Omega\left(n^6/\lambda^4\delta^3\right)$にし、学習率$\eta=\Omega(\lambda_0/n^2)$をとすると確率$1-\delta$で次式が成り立つ。ここで$\boldsymbol{u}_i(k)=f(\boldsymbol{x}_i;\boldsymbol{W}(k),\boldsymbol{a})(i=1,2,\dots,n$である。

$$
\|\boldsymbol{u}(k)-\boldsymbol{y}\|_2^2\leq \left(1-\frac{\eta\lambda_0}{2}\right)^k\|\boldsymbol{u}(0)-\boldsymbol{y}\|_2^2
$$

&lt;/div&gt;

&lt;h2 id=&quot;2の論文の設定&quot;&gt;[2]の論文の設定&lt;/h2&gt;

&lt;p&gt;実は[2]の論文で$L(\boldsymbol{W},\boldsymbol{a})$の挙動の式が得られている。[2]では高い確率で&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(\boldsymbol{W},\boldsymbol{a})\approx\frac{1}{2}\|(\boldsymbol{I}-\eta\boldsymbol{H}^\infty)^k\boldsymbol{y}\|_2^2&lt;/script&gt;

&lt;p&gt;が成り立つことが示されている。&lt;/p&gt;

&lt;h2 id=&quot;2の論文のキモ&quot;&gt;[2]の論文のキモ&lt;/h2&gt;

&lt;h2 id=&quot;2の論文の主張&quot;&gt;[2]の論文の主張&lt;/h2&gt;

&lt;h1 id=&quot;多層の場合の結果&quot;&gt;多層の場合の結果&lt;/h1&gt;

&lt;h1 id=&quot;参考文献&quot;&gt;参考文献&lt;/h1&gt;

&lt;p&gt;[1] &lt;a href=&quot;https://arxiv.org/abs/1810.02054&quot;&gt;GRADIENTDESCENTPROVABLYO PTIMIZES OVER-PARAMETERIZEDNEURALN ETWORKS&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[2] &lt;a href=&quot;https://arxiv.org/abs/1901.08584&quot;&gt;Fine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[3] &lt;a href=&quot;http://arxiv.org/abs/1811.03962&quot;&gt;A Convergence Theory for Deep Learning via Over-Parameterization&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[4] &lt;a href=&quot;http://arxiv.org/abs/1811.03804&quot;&gt;Gradient Descent Finds Global Minima of Deep Neural Networks&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[5] &lt;a href=&quot;https://arxiv.org/abs/1811.04918.&quot;&gt;Learning and Generalization in Overparameterized Neural Networks, Going Beyond Two Layers&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="machine-learning" /><summary type="html"></summary></entry><entry><title type="html">有界な確率変数 は sub-gaussian</title><link href="http://localhost:4000/2019/05/22/bounded-random.html" rel="alternate" type="text/html" title="有界な確率変数 は sub-gaussian" /><published>2019-05-22T00:00:00+09:00</published><updated>2019-05-22T00:00:00+09:00</updated><id>http://localhost:4000/2019/05/22/bounded-random</id><content type="html" xml:base="http://localhost:4000/2019/05/22/bounded-random.html">&lt;div class=&quot;theorem&quot;&gt;
&lt;div class=&quot;box-title&quot;&gt;定理&lt;/div&gt;
確率変数 $X$ が区間 $[a,b]$ で値を取るとする。このとき $X$ は パラメータ $\sigma=\frac{b-a}{2}$ で sub-gaussianになる。
&lt;/div&gt;

&lt;div class=&quot;proof&quot;&gt;
&lt;div class=&quot;box-title&quot;&gt;証明&lt;/div&gt;
$\psi(\lambda):=\log\mathbb{E}[e^{\lambda X}]$ と置くと。テイラーの定理より

$$
\psi(\lambda)　= \psi(0) + \psi^\prime(0)\lambda + \frac{\psi^{\prime\prime}(c)}{2}\lambda^2
$$

が成り立つ。ここで $\psi(0)=0, \psi^\prime(0)=\mathbb{E}[X]$ であるから、 $\sup_{\lambda\in\mathbb{R}}\psi^{\prime\prime}(\lambda)$ を評価すれば良い。

$$
\mathbb{E}_\lambda[f(X)]:=\frac{\mathbb{E}[f(X)e^{\lambda X}]}{\mathbb{E}[e^{\lambda X}]}
$$

と定めると、

$$
\psi^{\prime\prime}(\lambda)=\mathbb{E}_\lambda[(X-\mathbb{E}_\lambda[X])^2]
$$

と書ける。ここで $\lambda$ を固定して 実数 $t$ の二次関数 $\mathbb{E}_\lambda[(X-t)^2]$ を考える。

この関数は、$t=\mathbb{E}_\lambda[X]$ のときに最小になることがわかる。

したがって、

$$
\mathbb{E}_\lambda[(X-\mathbb{E}_\lambda[X])^2] \leq \mathbb{E}_\lambda\left[\left(X-\frac{b+a}{2}\right)^2\right]
\leq \frac{(b-a)^2}{4}
$$

これより $\mu=\mathbb{E}[X], \sigma=\frac{b-a}{2}$ と置くと

$$
\psi(\lambda) \leq  \mu\lambda + \frac{\sigma^2}{2}\lambda^2
$$

が すべての $\lambda\in\mathbb{R}$ で成立するので、$X$ はsub-gaussianとなる。

&lt;/div&gt;

&lt;h1 id=&quot;参考&quot;&gt;参考&lt;/h1&gt;
&lt;p&gt;次の本のExercise 2.4にあった問題。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cambridge.org/core/books/highdimensional-statistics/8A91ECEEC38F46DAB53E9FF8757C7A4E&quot;&gt;High-Dimensional Statistics
A Non-Asymptotic Viewpoint&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="math" /><category term="statistics" /><summary type="html">定理 確率変数 $X$ が区間 $[a,b]$ で値を取るとする。このとき $X$ は パラメータ $\sigma=\frac{b-a}{2}$ で sub-gaussianになる。</summary></entry><entry><title type="html">Maximum Mean Discrepancy (MMD)の性質</title><link href="http://localhost:4000/2019/04/18/maximum-mean-discrepancy.html" rel="alternate" type="text/html" title="Maximum Mean Discrepancy (MMD)の性質" /><published>2019-04-18T00:00:00+09:00</published><updated>2019-04-18T00:00:00+09:00</updated><id>http://localhost:4000/2019/04/18/maximum-mean-discrepancy</id><content type="html" xml:base="http://localhost:4000/2019/04/18/maximum-mean-discrepancy.html">&lt;h2 id=&quot;mmdの定義&quot;&gt;MMDの定義&lt;/h2&gt;

&lt;p&gt;MMDはカーネル法で登場する概念です。再生性を持つあるカーネル $k:\mathcal{X}\times\mathcal{X}\to\mathbb{R}$ に対してカーネル平均を次式で定義します。カーネル平均は定義の通り，$\mathcal{X}$ 上の実関数です。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;m_{X}(\cdot)=\int k(\cdot, x)dP_X(x)&lt;/script&gt;

&lt;h2 id=&quot;mmdの性質&quot;&gt;MMDの性質&lt;/h2&gt;

&lt;p&gt;工事中。&lt;/p&gt;

&lt;h2 id=&quot;参考資料&quot;&gt;参考資料&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.ism.ac.jp/~fukumizu/OsakaU2014/OsakaU_6kernelMean.pdf&quot;&gt;カーネル法入門
６．カーネル平均を用いたノンパラメトリック推論&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="math" /><category term="machine-learning" /><summary type="html">MMDの定義</summary></entry><entry><title type="html">A Bandit Framework for Optimal Selection of Reinforcement Learning Agentsを読んだ</title><link href="http://localhost:4000/2019/04/06/a-bandit-frame-work.html" rel="alternate" type="text/html" title="A Bandit Framework for Optimal Selection of Reinforcement Learning Agentsを読んだ" /><published>2019-04-06T00:00:00+09:00</published><updated>2019-04-06T00:00:00+09:00</updated><id>http://localhost:4000/2019/04/06/a-bandit-frame-work</id><content type="html" xml:base="http://localhost:4000/2019/04/06/a-bandit-frame-work.html">&lt;h2 id=&quot;要旨&quot;&gt;要旨&lt;/h2&gt;

&lt;p&gt;一般に強化学習を実世界に応用するとき、環境の情報は十分には得られない(ゲームのルールがわからない)。また環境から報酬を得ること自体のコストが高い(無制限に試行できない)。応用する問題によって適切なエージェントは異なるので、複数のエージェントから環境に最も適応した個体を選ぶバンディット問題とみなして最適なエージェントを選ぶことを提案している。その際、情報理論的には次の状態の分布とモデルのパラメータの分布の相互情報量が最大化となるもの(もっとも驚きが大きいものを)選ぶのが良い。ただ、モデルのパラメータの事後分布を直接計算することは難しいので、そこを変分近似した。&lt;/p&gt;

&lt;h2 id=&quot;bandit問題&quot;&gt;Bandit問題&lt;/h2&gt;

&lt;p&gt;$K$ 台のスロットマシンがそれぞれ期待値 $\mu_i$ (未知) に設定されているときに、最大の期待値 $\mu^\ast:=\max_{i} \mu_i$ を持つスロットマシンを探索するという問題です。なるべく探索回数を少なくして，得られる報酬も最大化するのが目標です。&lt;/p&gt;

&lt;p&gt;スロットマシンの設定によって名前がついている。[2]にわかりやすくかいてあって参考になりました。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;確率的Bandit&lt;/li&gt;
  &lt;li&gt;敵対的Bandit&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;強化学習としてのbandit問題&quot;&gt;強化学習としてのBandit問題&lt;/h2&gt;

&lt;p&gt;強化学習で扱うのは行動によって環境から報酬が得られるという状況において、何度か試行することで将来の報酬を最大化するような行動を探そうという設定の問題です。Bandit問題において毎回スロットマシンを引くことを行動とみなすと、Bandit問題は強化学習の問題とみなすことができます。&lt;/p&gt;

&lt;h2 id=&quot;本論文の貢献&quot;&gt;本論文の貢献&lt;/h2&gt;

&lt;p&gt;おそらく最適なエージェントの選択をバンディットとみなした点(？)&lt;/p&gt;

&lt;h2 id=&quot;参考文献&quot;&gt;参考文献&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;[1] &lt;a href=&quot;https://arxiv.org/abs/1902.03657&quot;&gt;A Bandit Framework for Optimal Selection of Reinforcement Learning Agents&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;[2] &lt;a href=&quot;http://ibisml.org/archive/ibis2014/ibis2014_bandit.pdf&quot;&gt;多腕バンディット問題の
理論とアルゴリズム&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="machine-learning" /><summary type="html">要旨</summary></entry><entry><title type="html">LightGBMの勉強をした。</title><link href="http://localhost:4000/2019/04/01/lightgbm.html" rel="alternate" type="text/html" title="LightGBMの勉強をした。" /><published>2019-04-01T00:00:00+09:00</published><updated>2019-04-01T00:00:00+09:00</updated><id>http://localhost:4000/2019/04/01/lightgbm</id><content type="html" xml:base="http://localhost:4000/2019/04/01/lightgbm.html">&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#特徴&quot; id=&quot;markdown-toc-特徴&quot;&gt;特徴&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#gossについて&quot; id=&quot;markdown-toc-gossについて&quot;&gt;GOSSについて&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#efbについて&quot; id=&quot;markdown-toc-efbについて&quot;&gt;EFBについて&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#参考文献&quot; id=&quot;markdown-toc-参考文献&quot;&gt;参考文献&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;特徴&quot;&gt;特徴&lt;/h2&gt;

&lt;p&gt;LighGBM では通常のGBDTに対してGradient-based One-Side Sampling (GOSS)とExclusive Feature Bundling (EFB) という2つの改善を行うことで精度を保ちつつ計算量を削減しています。&lt;/p&gt;

&lt;h2 id=&quot;gossについて&quot;&gt;GOSSについて&lt;/h2&gt;

&lt;p&gt;決定木を最適化するときにどこのしきい値で区切るのかを探索するパートが最も計算量がかかります。
これを計算するには本来はある閾値 $d$ で分割したときの分散 $V_{j}(d)$ を計算する必要があります。
この計算をするには全データを見る必要があるので計算量が大変大きいです。
LightGBMでは $V_{j}(d)$ の代わりに勾配の大きなところと勾配の小さなところからサンプリングして計算した分散 $\tilde{V}_{j}(d)$ を計算することにより、計算量を抑えています。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;V_{j|O}(d)=\frac{1}{n_ { O } } \left( \frac { \left( \sum _ { \left\{ x _ { i } \in O : x _ { i j } \leq d \right\} } g _ { i } \right) ^ { 2 } } { n _ { l | O } ^ { j } ( d ) } + \frac { \left( \sum _ { \left\{ x _ { i } \in O : x _ { i j } &gt; d \right\} } g _ { i } \right) ^ { 2 } } { n _ { r | O } ^ { j } ( d ) } \right)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tilde { V } _ { j } ( d ) = \frac { 1 } { n } \left( \frac { \left( \sum _ { x _ { i } \in A _ { l } } g _ { i } + \frac { 1 - a } { b } \sum _ { x _ { i } \in B _ { l } } g _ { i } \right) ^ { 2 } } { n _ { l } ^ { j } ( d ) } + \frac { \left( \sum _ { x _ { i } \in A _ { r } } g _ { i } + \frac { 1 - a } { b } \sum _ { x _ { i } \in B _ { r } } g _ { i } \right) ^ { 2 } } { n _ { r } ^ { j } ( d ) } \right)&lt;/script&gt;

&lt;p&gt;本来の分散との誤差も $\mathcal { O } \left( \frac { 1 } { n _ { l } ^ { j } ( d ) } + \frac { 1 } { n _ { r } ^ { j } ( d ) } + \frac { 1 } { \sqrt { n } } \right)$ なのでサンプルサイズ $n$ が大きければとても良い感じになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/GOSS.png&quot; alt=&quot;&quot; /&gt;
&lt;strong&gt;GOSSのアルゴリズム(原論文[1]より引用)&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;efbについて&quot;&gt;EFBについて&lt;/h2&gt;

&lt;p&gt;特徴量が高次元のとき、多くの場合ではそれはスパース性を持っています。つまり殆どの特徴量成分はゼロと考えることができます。よって、特徴量それぞれの成分の多くは互いに排他的、つまり、同時に非ゼロの値を取らないという性質が期待できそうです。&lt;/p&gt;

&lt;p&gt;同時に非ゼロにならないという性質を持っている特徴量成分たちを Bundle としてまとめてあげることで、特徴量の次元削減をするというのがEFBの主要なアイデアです。&lt;/p&gt;

&lt;p&gt;実際には成分同士が完全に排他的であることはないので、$K$ 回までは同時に非ゼロになることを許すという感じで適当な閾値をつくって Bundleを作っていきます。これをやっているのが、原論文 [1] のAlgorithm 3です。ただ Algorithm 3通りにやると計算量が $O(\text{特徴量数}^2)$ となってしまうので、Bundleを作るのではなく、非ゼロ成分の数でソートするみたいです。非ゼロ成分の個数が大きくなるほど、同時に非ゼロを取る確率もあがるからというイメージですね。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/greedybundling.png&quot; alt=&quot;&quot; /&gt;
&lt;strong&gt;Greedy Bundlingのアルゴリズム(原論文[1]より引用)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;そうやって作った Bundleを使って、特徴量を次元削減します。あるBundleを1次元のの特徴量にまとめるときに重要な条件は、まとめた特徴量から元の特徴量が復元できるというものです。例えば特徴量$A$ は $[0,10)$ をとり、特徴量 $B$ は$[0,20)$ を取るとします。 $A$ と $B$ をまとめるときに次のような操作をします。 まず、$B$ に 10 だけ足して (offset と原論文では呼んでいます)、範囲を $[10,30)$ にしてから、$[0, 30]$ の範囲で $A$ と $B$ をマージするという方法です。これを具体的に行っているのが Algorithm 4です。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/mef.png&quot; alt=&quot;&quot; /&gt;
&lt;strong&gt;Merge Exclusive Features(原論文[1]より引用)&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;参考文献&quot;&gt;参考文献&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;[1] &lt;a href=&quot;https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree&quot;&gt;LightGBM: A Highly Efficient Gradient Boosting Decision Tree&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="machine-learning" /><summary type="html"></summary></entry><entry><title type="html">Gradirnt Boosting Decision Treeの勉強をした。</title><link href="http://localhost:4000/2019/03/31/gdbt.html" rel="alternate" type="text/html" title="Gradirnt Boosting Decision Treeの勉強をした。" /><published>2019-03-31T00:00:00+09:00</published><updated>2019-03-31T00:00:00+09:00</updated><id>http://localhost:4000/2019/03/31/gdbt</id><content type="html" xml:base="http://localhost:4000/2019/03/31/gdbt.html">&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#動機&quot; id=&quot;markdown-toc-動機&quot;&gt;動機&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#決定木とは&quot; id=&quot;markdown-toc-決定木とは&quot;&gt;決定木とは&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#ブースティング木&quot; id=&quot;markdown-toc-ブースティング木&quot;&gt;ブースティング木&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#最急降下法&quot; id=&quot;markdown-toc-最急降下法&quot;&gt;最急降下法&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#勾配ブースティングとは&quot; id=&quot;markdown-toc-勾配ブースティングとは&quot;&gt;勾配ブースティングとは&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#勾配ブースティング決定木&quot; id=&quot;markdown-toc-勾配ブースティング決定木&quot;&gt;勾配ブースティング決定木&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#参考文献&quot; id=&quot;markdown-toc-参考文献&quot;&gt;参考文献&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;動機&quot;&gt;動機&lt;/h1&gt;

&lt;p&gt;Kaggleなどで話題となっているLightGBMなどのことを知るためにまず、勾配ブースティング決定木の勉強をした。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\DeclareMathOperator{\mathrm{argmin}}{arg\,min}&lt;/script&gt;

&lt;h1 id=&quot;決定木とは&quot;&gt;決定木とは&lt;/h1&gt;

&lt;p&gt;決定木では特徴量 $x$ を元に排反な $J$ 個の分割領域 $\{R_j\}_{j=1}^J$ を構成し、&lt;/p&gt;

&lt;p&gt;$x \in R_j$ のとき、予測値 $f(x)=\gamma_j$ を返す。&lt;/p&gt;

&lt;p&gt;これをまとめて表現すると、$\Theta := \{R_j, \gamma_j \}_{j=1}^J$ として、&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x) = T(x; \Theta) := \sum_{j=1}^J \gamma_j I(x\in R_j)&lt;/script&gt;

&lt;p&gt;とかける。&lt;/p&gt;

&lt;h1 id=&quot;ブースティング木&quot;&gt;ブースティング木&lt;/h1&gt;

&lt;p&gt;ブースティング木とは決定木をたくさん用意した予測モデルです。つまり&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F_M(x;\{\Theta_k\}_{k=1}^M) = \sum_{k=1}^M T(x;\Theta_k)&lt;/script&gt;

&lt;p&gt;で予測するようなモデルです。&lt;a href=&quot;https://maea2.github.io/adaboost&quot;&gt;Adaboostの記事&lt;/a&gt; でやったように$F$ を逐次最適化してみましょう。&lt;/p&gt;

&lt;p&gt;つまり、各 $\Theta_m$ を推定するときに&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\Theta}_1,\hat{\Theta}_2,\dots,\hat{\Theta}_{m-1}&lt;/script&gt;

&lt;p&gt;は得られているものとして(固定して)、&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\Theta}_m = \underset{\Theta_m}{\mathrm{argmin}} \sum_{i=1}^N L(y_i, F_M(x;\{\hat{\Theta}\}_{k=1}^{m-1})(x_i)+ T(x_i;\Theta_m))&lt;/script&gt;

&lt;p&gt;で推定してやろうということです。$L$は適当な損失関数です。&lt;/p&gt;

&lt;h1 id=&quot;最急降下法&quot;&gt;最急降下法&lt;/h1&gt;

&lt;p&gt;いま、関数$f$を使って予測したときの 損失関数の$x$についての条件付き期待値&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Phi(f) = \mathbb{E}_{y,x} \left[L(y, f(x))\right]&lt;/script&gt;

&lt;p&gt;がわかっているとします。&lt;/p&gt;

&lt;p&gt;$\Phi(f)$ を最小にするような予測関数 $f^\ast(x):=\mathrm{argmin}_f \Phi(f)$ がいま得たいものです。&lt;/p&gt;

&lt;p&gt;これを、&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F_M(x;\{f_k\}_{k=1}^M)=\sum_{k=1}^M f_m(x)&lt;/script&gt;

&lt;p&gt;の形で得ることを考えます。$f_1, f_2, f_3$ と少しづつ $f_i$ を増やして近似していくというイメージです。&lt;/p&gt;

&lt;p&gt;$f_i$ 一つ一つが弱学習器だと思ってください。&lt;/p&gt;

&lt;p&gt;いま、$f_1,\ldots,f_{m-1}$ まで得られているとします。&lt;/p&gt;

&lt;p&gt;いま、最急降下法を使って $f_m$ を計算することを考えます。$\Phi(f)$の$f$についての関数微分(functional gradient)を&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;g_m := \left.\frac{\partial \Phi}{\partial f}\right|_{f=F_{m-1}}&lt;/script&gt;

&lt;p&gt;と置くと、最急降下法によってもとまる $f_m$ は&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_m(x) = f_{m-1}(x) - \rho_m g_m(x)&lt;/script&gt;

&lt;p&gt;となります。$\rho_m$ は $\Phi(F_{m})$ が最小となるようにとります。&lt;/p&gt;

&lt;p&gt;つまり、&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\rho_m :=\mathrm{argmin}_{\rho}\Phi(F_{m-1}-\rho g_m)&lt;/script&gt;

&lt;p&gt;で定めます。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Phi(f) = \mathbb{E}_x[\mathbb{E}_y[L(y,f(x))|x]]&lt;/script&gt;

&lt;p&gt;と書き直すことができて、&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\phi(f(x))=\mathbb{E}_y[L(y,f(x))|x]&lt;/script&gt;

&lt;p&gt;と置くと、&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Phi(f) = \mathbb{E}_x[\phi(x)]&lt;/script&gt;

&lt;p&gt;と書き直す事ができます。$\phi$を使うと、$g_m(x)$を&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;g_m(x) = \left.\frac{\partial \phi(f(x))}{\partial f(x)}\right|_{f(x)=F(x;\{f_k\}_{k=1}^{m-1})}&lt;/script&gt;

&lt;p&gt;と書き直せます。これをもう少し書き換えると&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
g_m(x) &amp;= \left.\frac{\partial \phi(f(x))}{\partial f(x)}\right|_{f(x)=F(x;\{f_k\}_{k=1}^{m-1})} \\
&amp;= \mathbb{E}_y\left[\left.\frac{\partial L(y,f(x)|x)}{\partial f(x)}\right|_{f(x)=F(x;\{f_k\}_{k=1}^{m-1})}\right] (\text{微分と積分を入れ替えた})
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;となります。これを用いて、先程の$\rho_m$の最適化の式を書き直すと&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\rho_m = \mathrm{argmin}_{\rho}\mathbb{E}_{y,x}L(y, F_{m-1}-\rho g_m(x))&lt;/script&gt;

&lt;p&gt;とかける。&lt;/p&gt;

&lt;h1 id=&quot;勾配ブースティングとは&quot;&gt;勾配ブースティングとは&lt;/h1&gt;

&lt;p&gt;実際は $(x,y)$ の分布は未知であり、有限の訓練データ $\{(x_i,y_i)\}_{i=1}^N$ しか持っていません。&lt;/p&gt;

&lt;p&gt;なので、$g_m(x)$ の値は訓練データ点のところしかわかりません。よって、$\hat{\Theta}_m$ を推定するような問題を考えるとき、この方法は直接は使えません。&lt;/p&gt;

&lt;p&gt;次善の策を考えます。&lt;/p&gt;

&lt;p&gt;つまり有限個の最急勾配の値 $\{-g_m(x_i)\}_{i=1}^N$ と $\{T(x_i;\Theta)\}$ が訓練データ点においてだけでも近くなるように&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tilde{\Theta}_m :=\underset{\Theta}{\mathrm{argmin}}\sum_{i=1}^N (-g_m(x_i)-T(x_i;\Theta))^2&lt;/script&gt;

&lt;p&gt;で定めるという策です。&lt;/p&gt;

&lt;h2 id=&quot;勾配ブースティング決定木&quot;&gt;勾配ブースティング決定木&lt;/h2&gt;

&lt;p&gt;以上を踏まえて勾配ブースティング決定木の最適化アルゴリズムは次のようになります。&lt;/p&gt;

&lt;p&gt;(b)の部分が勾配情報との近くなるようにしている部分です。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/gbdt.png&quot; alt=&quot;&quot; /&gt;
&lt;strong&gt;勾配ブースティング決定木のアルゴリズム (カステラ本のp361より引用)&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;参考文献&quot;&gt;参考文献&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://statweb.stanford.edu/~jhf/ftp/trebst.pdf&quot;&gt;Greedy function approximation a gradient boosting machine&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://web.stanford.edu/~hastie/ElemStatLearn/&quot;&gt;The Elements of
Statistical Learning&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="machine-learning" /><category term="math" /><summary type="html"></summary></entry><entry><title type="html">Adaboostは指数損失を最小化している。</title><link href="http://localhost:4000/2019/03/30/adaboost.html" rel="alternate" type="text/html" title="Adaboostは指数損失を最小化している。" /><published>2019-03-30T00:00:00+09:00</published><updated>2019-03-30T00:00:00+09:00</updated><id>http://localhost:4000/2019/03/30/adaboost</id><content type="html" xml:base="http://localhost:4000/2019/03/30/adaboost.html">&lt;h1 id=&quot;adaboostとは&quot;&gt;Adaboostとは&lt;/h1&gt;

&lt;p&gt;Adaboostは単純な分類器(弱学習器)をたくさん集めて、分類モデルを学習するときのアルゴリズムの一つです。&lt;/p&gt;

&lt;p&gt;いま、$Y\in\{-1,1\}$ を正解ラベル、$X\in\mathcal{X}$ を特徴量とする2値分類問題を考えます。&lt;/p&gt;

&lt;p&gt;$G_m:\mathcal{X}\to\{-1,1\}$ となる分類器を$M$個(m=1,2,\ldots,M)用意します。&lt;/p&gt;

&lt;p&gt;これらを用いて分類器 $G(x)$ を&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;G(x)=\mathrm{sign}\left(\sum_{m=1}^M \alpha_mG_m(x)\right)&lt;/script&gt;

&lt;p&gt;で作ることを考えます。&lt;/p&gt;

&lt;p&gt;訓練データ ${x_i,y_i}_{i=1}^N\subset \{-1,1\}\times\mathcal{X}$ が得られているとします。&lt;/p&gt;

&lt;p&gt;このとき、$\{G_m\}&lt;em&gt;{m=1}^M, \{\alpha_m\}&lt;/em&gt;{m=1}^M$ を学習するのが目標です。&lt;/p&gt;

&lt;p&gt;Adaboostは次のようなアルゴリズムです。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/adaboost.png&quot; alt=&quot;fig&quot; /&gt;
&lt;strong&gt;Adaboostのアルゴリズム(カステラ本p339より引用)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Adaboostでは各訓練データに対して重み$w_i$を $m$ について逐次更新します。各 $m$ で $w_i$ に従った重み付きのフィッティングを行い $G_m$ を決定します。&lt;/p&gt;

&lt;p&gt;イメージとしては、前回で誤分類したデータに対しては重みを重く、正解したデータに対しては重みは変えないというような感じで $w_i$ を決定しています。&lt;/p&gt;

&lt;h1 id=&quot;alpha_m-の根拠&quot;&gt;$\alpha_m$ の根拠&lt;/h1&gt;

&lt;p&gt;$w_i$ を更新する際に $\exp(\alpha_m\cdot I(y_i\neq G_m(x_i)))$ 倍していますがこれにはどんな根拠があるのでしょうか。実は指数損失の最小化を考えると、自然とこの値が導かれるというのが今日これから書く内容です。&lt;/p&gt;

&lt;h1 id=&quot;指数損失の最小化から-alpha_m-を出す&quot;&gt;指数損失の最小化から $\alpha_m$ を出す&lt;/h1&gt;

&lt;p&gt;指数損失とは&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\exp(-yG(x))&lt;/script&gt;

&lt;p&gt;で定義される損失です。&lt;/p&gt;

&lt;p&gt;いま&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_m(x) := \sum_{i=1}^m \beta_i G_i(x)&lt;/script&gt;

&lt;p&gt;と定めて、各 $m$ に対して、&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(\beta_m, G_m)　:= \mathrm{argmin}_{\beta, G} \sum_{i=1}^N \exp(-y_i(f_{m-1}(x_i)+\beta G(x_i)))&lt;/script&gt;

&lt;p&gt;で逐次的に $(\beta_m, G_m)$ を決定していくことを考えます。&lt;/p&gt;

&lt;p&gt;$w_i^{(m)}:=\exp(-y_if_{m-1}(x_i))$ と置くと、&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(\beta_m, G_m)　:= \mathrm{argmin}_{\beta, G} \sum_{i=1}^N w_i^{(m)}\exp(-y_i\beta G(x_i))&lt;/script&gt;

&lt;p&gt;と書き換える事ができます。$(\beta_m, G_m)$　は指数損失の重み付き和を最小にするように決定しようというわけです。&lt;/p&gt;

&lt;p&gt;ここで指数損失の重み付き和について次のような書き換えを行います。&lt;/p&gt;

&lt;div class=&quot;slide&quot;&gt;

$$
\begin{align}
&amp;amp;\sum_{i=1}^N w_i^{(m)}\exp(-y_i\beta G(x_i))\\
=&amp;amp;\sum_{y_i=G_i(x)} w_i^{(m)}\exp(-y_i\beta G(x_i)) +
\sum_{y_i\neq G_i(x)} w_i^{(m)}\exp(-y_i\beta G(x_i)))\\
=&amp;amp;\sum_{i=1}^N w_i^{(m)}\exp(-y_i\beta G(x_i))(1-I(y_i\neq G_m(x_i))) +
\sum_{y_i\neq G_i(x)} w_i^{(m)}\exp(-y_i\beta G(x_i))I(y_i\neq G_m(x_i))\\
=&amp;amp;(e^{\beta}+e^{-\beta})\sum_{i=1}^N w_i^{(m)}I(y_i\neq G_m(x_i)) + \sum_{i=1}^N w_i^{(m)}e^{-\beta}
\end{align}
$$

&lt;/div&gt;

&lt;p&gt;これより $G_m$は $\sum_{i=1}^N w_i^{(m)}I(y_i\neq G_m(x_i))$ を最小にするように決めれば良いことがわかります。そのように決定した $G_m$ を代入し、それを $\beta$ について最小化するような $\beta$ を求めれば $\beta_m$ も決定します。&lt;/p&gt;

&lt;p&gt;上の式を $\beta$ について偏微分して整理すると&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;e^{2\beta} = \frac{\sum_{i=1}^N w_i^{(m)}(1-I(y_i\neq G_m(x_i)))}{\sum_{i=1}^N w_i^{(m)}I(y_i\neq G_m(x_i))}&lt;/script&gt;

&lt;p&gt;となります。いま重み付き誤差率 $\mathrm{err}_m$ を&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathrm{err}_m = \frac{\sum_{i=1}^N w_i^{(m)}I(y_i\neq G_m(x_i))}{\sum_{i=1}^N w_i^{(m)}}&lt;/script&gt;

&lt;p&gt;で定めると&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
&amp;e^{2\beta} = \frac{1-\mathrm{err}_m}{\mathrm{err}_m}\\
&amp;\therefore \beta_m = \frac{1}{2} \log\left( \frac{1-\mathrm{err}_m}{\mathrm{err}_m}\right)
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;となります。$\alpha = 2\beta_m$ と置けば、Adaboostの $\alpha_m$ が出てきました。&lt;/p&gt;

&lt;h1 id=&quot;参考文献&quot;&gt;参考文献&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://web.stanford.edu/~hastie/ElemStatLearn/&quot;&gt;The Elements of
Statistical Learning 10章&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;/p&gt;</content><author><name></name></author><category term="machine-learning" /><category term="math" /><summary type="html">Adaboostとは</summary></entry></feed>