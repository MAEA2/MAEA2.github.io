<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-06-07T11:46:34+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">maea2 blog</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</subtitle><entry><title type="html">単位根検定について</title><link href="http://localhost:4000/2020/05/10/unit-root-test.html" rel="alternate" type="text/html" title="単位根検定について" /><published>2020-05-10T00:00:00+09:00</published><updated>2020-05-10T00:00:00+09:00</updated><id>http://localhost:4000/2020/05/10/unit-root-test</id><content type="html" xml:base="http://localhost:4000/2020/05/10/unit-root-test.html">&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#単位根検定とは&quot; id=&quot;markdown-toc-単位根検定とは&quot;&gt;単位根検定とは&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#単位根検定&quot; id=&quot;markdown-toc-単位根検定&quot;&gt;単位根検定&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#df検定dickey-fuller-test&quot; id=&quot;markdown-toc-df検定dickey-fuller-test&quot;&gt;DF検定(Dickey-Fuller Test)&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#df分布&quot; id=&quot;markdown-toc-df分布&quot;&gt;DF分布&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;単位根検定とは&quot;&gt;単位根検定とは&lt;/h1&gt;

&lt;p&gt;期待値と自己共分散が$t$によらず一定であるような場合、その確率過程は弱定常過程であるという。
定常過程は定義からその変化が時刻に依存することがないので、平均回帰的(平均に戻ろうとする性質)でありかつ
トレンド(時刻に依存した変化)を持ちません。
しかし、時系列データのなかには必ずしも定常過程ではかけないようなものも存在します。
例えば株価や為替レートなどがその例です。そのような時系列データをモデリングする手法の最も基本的なものとして単位根過程があります。
これは差分は定常過程であることを仮定する確率モデルです。&lt;/p&gt;

&lt;div class=&quot;definition&quot;&gt;
&lt;div class=&quot;box-title&quot;&gt;単位根過程&lt;/div&gt;
確率過程$\{y_t\}$がすべての$t$について

$$
\Delta y_t:=y_t-y_{t-1}
$$

が弱定常過程になっているとき、$\{y_t\}$は単位根過程であるという。
&lt;/div&gt;

&lt;h1 id=&quot;単位根検定&quot;&gt;単位根検定&lt;/h1&gt;

&lt;p&gt;考えている確率過程が単位根過程であるか定常過程であるかを検定したいことがある。単位根過程には平均回帰性がないので、たとえば一度大きな変動が起きるとそれはその影響は
ランダムネスで打ち消されることはなく残ってしまう。反対に定常過程であれば一度大きな変動があっても時間が経てば平均に戻っていくはずである。
したがって、考えている確率過程が定常的に振る舞っているのか、単位根過程であるのかを検定する手段の一つとして単位根検定がある。
単位根検定では考えている確率過程が少なくとも単位根過程であることを仮定する。(定常過程ならば単位根過程である)&lt;/p&gt;

&lt;h2 id=&quot;df検定dickey-fuller-test&quot;&gt;DF検定(Dickey-Fuller Test)&lt;/h2&gt;

&lt;p&gt;考えている時系列の期待値が0であるかやトレンドを持つかどうかによって単位根検定にもバリエーションがある。
ここでは考えている確率過程の平均が0でトレンドを持たない場合を考える。すなわち、&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
&amp;H_0: y_t=y_{t-1}+u_t\\
&amp;H_1: y_t=\rho y_{t-1}+u_t, |\rho|&lt;1 
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;$u_t$は平均0の確率過程である。これは$\rho$についての検定と見ることができて、$H_0:\rho=1, H_1:|\rho|&amp;lt;1$に対応している。&lt;/p&gt;

&lt;h3 id=&quot;df分布&quot;&gt;DF分布&lt;/h3&gt;

&lt;p&gt;$\rho$のOLS推定量を$\hat{\rho}$とすると、サンプルサイズが$T$である場合は$\rho=1$の元での漸近分布として&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tau_{\rho=1}=T(\hat{\rho}-1)\overset{d}{\to}\frac{\frac{1}{2}\left\{[W(1)]^2-1\right\}}{\int_{0}^1[W(r)]^2dr}&lt;/script&gt;

&lt;p&gt;が成立することが知られており($\overset{d}{to}$は分布収束)、この漸近分布をDF分布という。検定のときはDF分布の棄却点を設定し、
$\tau_{\rho=1}$が棄却点より小さい場合は$H_0$を棄却する。&lt;/p&gt;</content><author><name></name></author><category term="math" /><category term="statistics" /><summary type="html"></summary></entry><entry><title type="html">ニューラルネットのover-parameterizationについて最近の論文を読んだ。</title><link href="http://localhost:4000/2020/05/04/over-parameterization.html" rel="alternate" type="text/html" title="ニューラルネットのover-parameterizationについて最近の論文を読んだ。" /><published>2020-05-04T00:00:00+09:00</published><updated>2020-05-04T00:00:00+09:00</updated><id>http://localhost:4000/2020/05/04/over-parameterization</id><content type="html" xml:base="http://localhost:4000/2020/05/04/over-parameterization.html">&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#モチベーション&quot; id=&quot;markdown-toc-モチベーション&quot;&gt;モチベーション&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#2層の場合の結果&quot; id=&quot;markdown-toc-2層の場合の結果&quot;&gt;2層の場合の結果&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#1の論文の設定&quot; id=&quot;markdown-toc-1の論文の設定&quot;&gt;[1]の論文の設定&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#neural-tangent-kernel&quot; id=&quot;markdown-toc-neural-tangent-kernel&quot;&gt;Neural Tangent Kernel&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#1の論文のキモ&quot; id=&quot;markdown-toc-1の論文のキモ&quot;&gt;[1]の論文のキモ&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#1の論文の主張&quot; id=&quot;markdown-toc-1の論文の主張&quot;&gt;[1]の論文の主張&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2の論文の設定&quot; id=&quot;markdown-toc-2の論文の設定&quot;&gt;[2]の論文の設定&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2の論文のキモ&quot; id=&quot;markdown-toc-2の論文のキモ&quot;&gt;[2]の論文のキモ&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2の論文の主張&quot; id=&quot;markdown-toc-2の論文の主張&quot;&gt;[2]の論文の主張&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#多層の場合の結果&quot; id=&quot;markdown-toc-多層の場合の結果&quot;&gt;多層の場合の結果&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#参考文献&quot; id=&quot;markdown-toc-参考文献&quot;&gt;参考文献&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;モチベーション&quot;&gt;モチベーション&lt;/h1&gt;

&lt;p&gt;近年用いられるニューラルネットではデータ数に対してパラメータ数が非常に多い状況が多い。これは既存の学習理論の枠組みとは相反する。パラメータ数が非常に多いモデルのことをover-parameterized modelという。&lt;/p&gt;

&lt;h1 id=&quot;2層の場合の結果&quot;&gt;2層の場合の結果&lt;/h1&gt;

&lt;p&gt;[1]では2層のニューラルネットで二乗損失を用いた場合に十分にユニット数で$m$が大きければ、勾配法による学習によって損失を限りなく小さくできることを示している。&lt;/p&gt;

&lt;h2 id=&quot;1の論文の設定&quot;&gt;[1]の論文の設定&lt;/h2&gt;

&lt;p&gt;2層ニューラルネットは次式で定義される。ここで$\sigma$はReLUである。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(\boldsymbol{x};\boldsymbol{W},\boldsymbol{a})=\frac{1}{\sqrt{m}}\sum_{r=1}^ma_i\sigma(\boldsymbol{w}_r^\top\boldsymbol{x})&lt;/script&gt;

&lt;p&gt;次の二乗損失を最小化する。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(\boldsymbol{W}, \boldsymbol{a}) = \sum_{i=1}^n \frac{1}{2}\left(y_i-f(\boldsymbol{x}_i;\boldsymbol{W}, \boldsymbol{a})\right)^2&lt;/script&gt;

&lt;p&gt;学習は勾配法で行う。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol{W}(k+1) = \boldsymbol{W}(k)-\eta\frac{\partial L(\boldsymbol{W}(k), \boldsymbol{a})}{\partial\boldsymbol{W}(k)}&lt;/script&gt;

&lt;h2 id=&quot;neural-tangent-kernel&quot;&gt;Neural Tangent Kernel&lt;/h2&gt;

&lt;p&gt;いま、損失を$L(\boldsymbol{W},\boldsymbol{a})=\sum_{i=1}^n \ell_i(f_{\boldsymbol{W}}(\boldsymbol{x}_i);\boldsymbol{a})$で定めておく。$\boldsymbol{a}$は固定するのがポイントになっている。Neural Tangent Kernelは2層ニューラルネットの勾配流を考えると出てくる量
で解析の際に重要な役割を果たす。学習のステップ幅を限りなく小さくすると、次の勾配流の式がでてくる。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\mathrm{d}\boldsymbol{w}_r}{\mathrm{d}t}=-\nabla_{\boldsymbol{w}_r} L(\boldsymbol{W},\boldsymbol{a})&lt;/script&gt;

&lt;p&gt;ここで、&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\frac{\mathrm{d}\boldsymbol{w}_r}{\mathrm{d}t}&amp;=-\nabla_{\boldsymbol{w}_r} L(\boldsymbol{W},\boldsymbol{a})\\
&amp;=-\sum_{i=1}^n \nabla_{\boldsymbol{w}_r} \ell_i(f_{\boldsymbol{W}}(\boldsymbol{x}_i);\boldsymbol{a})\\
&amp;=-\sum_{i=1}^n \frac{\mathrm{d}\ell_i(f_{\boldsymbol{W}})}{\mathrm{d}f_{\boldsymbol{W}}}a_r\nabla_{\boldsymbol{w}_r}\sigma(\boldsymbol{w}_r^\top\boldsymbol{x}_i)\\

\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;したがって、&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\frac{\mathrm{d} f_{\boldsymbol{W}}(\boldsymbol{x})}{\mathrm{d}t}=&amp;\sum_{r=1}^m\nabla_{\boldsymbol{w}_r}^\top f_{\boldsymbol{W}}\frac{\mathrm{d}\boldsymbol{w}_r}{\mathrm{d}t}\\
=&amp;\sum_{r=1}^m\nabla_{\boldsymbol{w}_r}^\top f_{\boldsymbol{W}}\left(-\sum_{i=1}^n \frac{\mathrm{d}\ell_i(f_{\boldsymbol{W}})}{\mathrm{d}f_{\boldsymbol{W}}}\nabla_{\boldsymbol{w}_r}\sigma(\boldsymbol{w}_r^\top\boldsymbol{x}_i)\right)\\
=&amp;\sum_{r=1}^m\nabla_{\boldsymbol{w}_r}^\top f_{\boldsymbol{W}}(\boldsymbol{x})\left(-\sum_{i=1}^n \frac{\mathrm{d}\ell_i(f_{\boldsymbol{W}})}{\mathrm{d}f_{\boldsymbol{W}}}\nabla_{\boldsymbol{w}_r}\sigma(\boldsymbol{w}_r^\top\boldsymbol{x}_i)\right)\\
=&amp;\sum_{r=1}^ma_r\nabla_{\boldsymbol{w}_r}^\top\sigma(\boldsymbol{w}_r^\top\boldsymbol{x})\left(-\sum_{i=1}^n \frac{\mathrm{d}\ell_i(f_{\boldsymbol{W}})}{\mathrm{d}f_{\boldsymbol{W}}}\nabla_{w_r}\sigma(\boldsymbol{w}_r^\top\boldsymbol{x}_i)\right)\\
=&amp;-\sum_{i=1}^n\frac{\mathrm{d}\ell_i(f_{\boldsymbol{W}})}{\mathrm{d}f_{\boldsymbol{W}}}\underbrace{\sum_{r=1}^ma_r\nabla_{\boldsymbol{w}_r}^\top\sigma(\boldsymbol{w}_r^\top\boldsymbol{x}) \nabla_{w_r}\sigma(\boldsymbol{w}_r^\top\boldsymbol{x}_i)}_{=:k_{\boldsymbol{W}}(\boldsymbol{x},\boldsymbol{x}_i)}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;$k_{\boldsymbol{W}}$をNeural Tangent Kernelという。多層の場合も中間層の出力を考えれば同様の手順で求めることができるはず。&lt;/p&gt;

&lt;h2 id=&quot;1の論文のキモ&quot;&gt;[1]の論文のキモ&lt;/h2&gt;

&lt;p&gt;他の論文でも繰り返し出てくるが、次のGram matrix $\boldsymbol{H}^\infty$が非常に重要な役割を果たす。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol{H}^\infty_{i,j} = \mathbb{E}_{\boldsymbol{w}\sim\mathcal{N}(\boldsymbol{0},\boldsymbol{I})}\left[\boldsymbol{x}_i^\top\boldsymbol{x}_j\mathbb{I}_{\left\{\boldsymbol{w}^\top\boldsymbol{x}_i\geq 0\text{ and } \boldsymbol{w}^\top\boldsymbol{x}_j\geq 0\right\}}\right]&lt;/script&gt;

&lt;h2 id=&quot;1の論文の主張&quot;&gt;[1]の論文の主張&lt;/h2&gt;

&lt;div class=&quot;box&quot;&gt;

$\boldsymbol{w}_r\sim\mathcal{N}(\boldsymbol{0},\boldsymbol{I})$
, $a_r\sim\mathrm{unif}(0,1)$で初期化された2層ニューラルネットはユニット数を$m=\Omega\left(n^6/\lambda^4\delta^3\right)$にし、学習率$\eta=\Omega(\lambda_0/n^2)$をとすると確率$1-\delta$で次式が成り立つ。ここで$\boldsymbol{u}_i(k)=f(\boldsymbol{x}_i;\boldsymbol{W}(k),\boldsymbol{a})(i=1,2,\dots,n$である。

$$
\|\boldsymbol{u}(k)-\boldsymbol{y}\|_2^2\leq \left(1-\frac{\eta\lambda_0}{2}\right)^k\|\boldsymbol{u}(0)-\boldsymbol{y}\|_2^2
$$

&lt;/div&gt;

&lt;h2 id=&quot;2の論文の設定&quot;&gt;[2]の論文の設定&lt;/h2&gt;

&lt;p&gt;実は[2]の論文で$L(\boldsymbol{W},\boldsymbol{a})$の挙動の式が得られている。[2]では高い確率で&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(\boldsymbol{W},\boldsymbol{a})\approx\frac{1}{2}\|(\boldsymbol{I}-\eta\boldsymbol{H}^\infty)^k\boldsymbol{y}\|_2^2&lt;/script&gt;

&lt;p&gt;が成り立つことが示されている。&lt;/p&gt;

&lt;h2 id=&quot;2の論文のキモ&quot;&gt;[2]の論文のキモ&lt;/h2&gt;

&lt;h2 id=&quot;2の論文の主張&quot;&gt;[2]の論文の主張&lt;/h2&gt;

&lt;h1 id=&quot;多層の場合の結果&quot;&gt;多層の場合の結果&lt;/h1&gt;

&lt;h1 id=&quot;参考文献&quot;&gt;参考文献&lt;/h1&gt;

&lt;p&gt;[1] &lt;a href=&quot;https://arxiv.org/abs/1810.02054&quot;&gt;GRADIENTDESCENTPROVABLYO PTIMIZES OVER-PARAMETERIZEDNEURALN ETWORKS&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[2] &lt;a href=&quot;https://arxiv.org/abs/1901.08584&quot;&gt;Fine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[3] &lt;a href=&quot;http://arxiv.org/abs/1811.03962&quot;&gt;A Convergence Theory for Deep Learning via Over-Parameterization&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[4] &lt;a href=&quot;http://arxiv.org/abs/1811.03804&quot;&gt;Gradient Descent Finds Global Minima of Deep Neural Networks&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[5] &lt;a href=&quot;https://arxiv.org/abs/1811.04918.&quot;&gt;Learning and Generalization in Overparameterized Neural Networks, Going Beyond Two Layers&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="machine-learning" /><summary type="html"></summary></entry><entry><title type="html">有界な確率変数 は sub-gaussian</title><link href="http://localhost:4000/2019/05/22/bounded-random.html" rel="alternate" type="text/html" title="有界な確率変数 は sub-gaussian" /><published>2019-05-22T00:00:00+09:00</published><updated>2019-05-22T00:00:00+09:00</updated><id>http://localhost:4000/2019/05/22/bounded-random</id><content type="html" xml:base="http://localhost:4000/2019/05/22/bounded-random.html">&lt;div class=&quot;theorem&quot;&gt;
&lt;div class=&quot;box-title&quot;&gt;定理&lt;/div&gt;
確率変数 $X$ が区間 $[a,b]$ で値を取るとする。このとき $X$ は パラメータ $\sigma=\frac{b-a}{2}$ で sub-gaussianになる。
&lt;/div&gt;

&lt;div class=&quot;proof&quot;&gt;
&lt;div class=&quot;box-title&quot;&gt;証明&lt;/div&gt;
$\psi(\lambda):=\log\mathbb{E}[e^{\lambda X}]$ と置くと。テイラーの定理より

$$
\psi(\lambda)　= \psi(0) + \psi^\prime(0)\lambda + \frac{\psi^{\prime\prime}(c)}{2}\lambda^2
$$

が成り立つ。ここで $\psi(0)=0, \psi^\prime(0)=\mathbb{E}[X]$ であるから、 $\sup_{\lambda\in\mathbb{R}}\psi^{\prime\prime}(\lambda)$ を評価すれば良い。

$$
\mathbb{E}_\lambda[f(X)]:=\frac{\mathbb{E}[f(X)e^{\lambda X}]}{\mathbb{E}[e^{\lambda X}]}
$$

と定めると、

$$
\psi^{\prime\prime}(\lambda)=\mathbb{E}_\lambda[(X-\mathbb{E}_\lambda[X])^2]
$$

と書ける。ここで $\lambda$ を固定して 実数 $t$ の二次関数 $\mathbb{E}_\lambda[(X-t)^2]$ を考える。

この関数は、$t=\mathbb{E}_\lambda[X]$ のときに最小になることがわかる。

したがって、

$$
\mathbb{E}_\lambda[(X-\mathbb{E}_\lambda[X])^2] \leq \mathbb{E}_\lambda\left[\left(X-\frac{b+a}{2}\right)^2\right]
\leq \frac{(b-a)^2}{4}
$$

これより $\mu=\mathbb{E}[X], \sigma=\frac{b-a}{2}$ と置くと

$$
\psi(\lambda) \leq  \mu\lambda + \frac{\sigma^2}{2}\lambda^2
$$

が すべての $\lambda\in\mathbb{R}$ で成立するので、$X$ はsub-gaussianとなる。

&lt;/div&gt;

&lt;h1 id=&quot;参考&quot;&gt;参考&lt;/h1&gt;
&lt;p&gt;次の本のExercise 2.4にあった問題。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cambridge.org/core/books/highdimensional-statistics/8A91ECEEC38F46DAB53E9FF8757C7A4E&quot;&gt;High-Dimensional Statistics
A Non-Asymptotic Viewpoint&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="math" /><category term="statistics" /><summary type="html">定理 確率変数 $X$ が区間 $[a,b]$ で値を取るとする。このとき $X$ は パラメータ $\sigma=\frac{b-a}{2}$ で sub-gaussianになる。</summary></entry><entry><title type="html">Maximum Mean Discrepancy (MMD)の性質</title><link href="http://localhost:4000/2019/04/18/maximum-mean-discrepancy.html" rel="alternate" type="text/html" title="Maximum Mean Discrepancy (MMD)の性質" /><published>2019-04-18T00:00:00+09:00</published><updated>2019-04-18T00:00:00+09:00</updated><id>http://localhost:4000/2019/04/18/maximum-mean-discrepancy</id><content type="html" xml:base="http://localhost:4000/2019/04/18/maximum-mean-discrepancy.html">&lt;h2 id=&quot;mmdの定義&quot;&gt;MMDの定義&lt;/h2&gt;

&lt;p&gt;MMDはカーネル法で登場する概念です。再生性を持つあるカーネル $k:\mathcal{X}\times\mathcal{X}\to\mathbb{R}$ に対してカーネル平均を次式で定義します。カーネル平均は定義の通り，$\mathcal{X}$ 上の実関数です。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;m_{X}(\cdot)=\int k(\cdot, x)dP_X(x)&lt;/script&gt;

&lt;h2 id=&quot;mmdの性質&quot;&gt;MMDの性質&lt;/h2&gt;

&lt;p&gt;工事中。&lt;/p&gt;

&lt;h2 id=&quot;参考資料&quot;&gt;参考資料&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.ism.ac.jp/~fukumizu/OsakaU2014/OsakaU_6kernelMean.pdf&quot;&gt;カーネル法入門
６．カーネル平均を用いたノンパラメトリック推論&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="math" /><category term="machine-learning" /><summary type="html">MMDの定義</summary></entry><entry><title type="html">A Bandit Framework for Optimal Selection of Reinforcement Learning Agentsを読んだ</title><link href="http://localhost:4000/2019/04/06/a-bandit-frame-work.html" rel="alternate" type="text/html" title="A Bandit Framework for Optimal Selection of Reinforcement Learning Agentsを読んだ" /><published>2019-04-06T00:00:00+09:00</published><updated>2019-04-06T00:00:00+09:00</updated><id>http://localhost:4000/2019/04/06/a-bandit-frame-work</id><content type="html" xml:base="http://localhost:4000/2019/04/06/a-bandit-frame-work.html">&lt;h2 id=&quot;要旨&quot;&gt;要旨&lt;/h2&gt;

&lt;p&gt;一般に強化学習を実世界に応用するとき、環境の情報は十分には得られない(ゲームのルールがわからない)。また環境から報酬を得ること自体のコストが高い(無制限に試行できない)。応用する問題によって適切なエージェントは異なるので、複数のエージェントから環境に最も適応した個体を選ぶバンディット問題とみなして最適なエージェントを選ぶことを提案している。その際、情報理論的には次の状態の分布とモデルのパラメータの分布の相互情報量が最大化となるもの(もっとも驚きが大きいものを)選ぶのが良い。ただ、モデルのパラメータの事後分布を直接計算することは難しいので、そこを変分近似した。&lt;/p&gt;

&lt;h2 id=&quot;bandit問題&quot;&gt;Bandit問題&lt;/h2&gt;

&lt;p&gt;$K$ 台のスロットマシンがそれぞれ期待値 $\mu_i$ (未知) に設定されているときに、最大の期待値 $\mu^\ast:=\max_{i} \mu_i$ を持つスロットマシンを探索するという問題です。なるべく探索回数を少なくして，得られる報酬も最大化するのが目標です。&lt;/p&gt;

&lt;p&gt;スロットマシンの設定によって名前がついている。[2]にわかりやすくかいてあって参考になりました。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;確率的Bandit&lt;/li&gt;
  &lt;li&gt;敵対的Bandit&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;強化学習としてのbandit問題&quot;&gt;強化学習としてのBandit問題&lt;/h2&gt;

&lt;p&gt;強化学習で扱うのは行動によって環境から報酬が得られるという状況において、何度か試行することで将来の報酬を最大化するような行動を探そうという設定の問題です。Bandit問題において毎回スロットマシンを引くことを行動とみなすと、Bandit問題は強化学習の問題とみなすことができます。&lt;/p&gt;

&lt;h2 id=&quot;本論文の貢献&quot;&gt;本論文の貢献&lt;/h2&gt;

&lt;p&gt;おそらく最適なエージェントの選択をバンディットとみなした点(？)&lt;/p&gt;

&lt;h2 id=&quot;参考文献&quot;&gt;参考文献&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;[1] &lt;a href=&quot;https://arxiv.org/abs/1902.03657&quot;&gt;A Bandit Framework for Optimal Selection of Reinforcement Learning Agents&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;[2] &lt;a href=&quot;http://ibisml.org/archive/ibis2014/ibis2014_bandit.pdf&quot;&gt;多腕バンディット問題の
理論とアルゴリズム&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="machine-learning" /><summary type="html">要旨</summary></entry><entry><title type="html">LightGBMの勉強をした。</title><link href="http://localhost:4000/2019/04/01/lightgbm.html" rel="alternate" type="text/html" title="LightGBMの勉強をした。" /><published>2019-04-01T00:00:00+09:00</published><updated>2019-04-01T00:00:00+09:00</updated><id>http://localhost:4000/2019/04/01/lightgbm</id><content type="html" xml:base="http://localhost:4000/2019/04/01/lightgbm.html">&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#特徴&quot; id=&quot;markdown-toc-特徴&quot;&gt;特徴&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#gossについて&quot; id=&quot;markdown-toc-gossについて&quot;&gt;GOSSについて&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#efbについて&quot; id=&quot;markdown-toc-efbについて&quot;&gt;EFBについて&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#参考文献&quot; id=&quot;markdown-toc-参考文献&quot;&gt;参考文献&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;特徴&quot;&gt;特徴&lt;/h2&gt;

&lt;p&gt;LighGBM では通常のGBDTに対してGradient-based One-Side Sampling (GOSS)とExclusive Feature Bundling (EFB) という2つの改善を行うことで精度を保ちつつ計算量を削減しています。&lt;/p&gt;

&lt;h2 id=&quot;gossについて&quot;&gt;GOSSについて&lt;/h2&gt;

&lt;p&gt;決定木を最適化するときにどこのしきい値で区切るのかを探索するパートが最も計算量がかかります。
これを計算するには本来はある閾値 $d$ で分割したときの分散 $V_{j}(d)$ を計算する必要があります。
この計算をするには全データを見る必要があるので計算量が大変大きいです。
LightGBMでは $V_{j}(d)$ の代わりに勾配の大きなところと勾配の小さなところからサンプリングして計算した分散 $\tilde{V}_{j}(d)$ を計算することにより、計算量を抑えています。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;V_{j|O}(d)=\frac{1}{n_ { O } } \left( \frac { \left( \sum _ { \left\{ x _ { i } \in O : x _ { i j } \leq d \right\} } g _ { i } \right) ^ { 2 } } { n _ { l | O } ^ { j } ( d ) } + \frac { \left( \sum _ { \left\{ x _ { i } \in O : x _ { i j } &gt; d \right\} } g _ { i } \right) ^ { 2 } } { n _ { r | O } ^ { j } ( d ) } \right)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tilde { V } _ { j } ( d ) = \frac { 1 } { n } \left( \frac { \left( \sum _ { x _ { i } \in A _ { l } } g _ { i } + \frac { 1 - a } { b } \sum _ { x _ { i } \in B _ { l } } g _ { i } \right) ^ { 2 } } { n _ { l } ^ { j } ( d ) } + \frac { \left( \sum _ { x _ { i } \in A _ { r } } g _ { i } + \frac { 1 - a } { b } \sum _ { x _ { i } \in B _ { r } } g _ { i } \right) ^ { 2 } } { n _ { r } ^ { j } ( d ) } \right)&lt;/script&gt;

&lt;p&gt;本来の分散との誤差も $\mathcal { O } \left( \frac { 1 } { n _ { l } ^ { j } ( d ) } + \frac { 1 } { n _ { r } ^ { j } ( d ) } + \frac { 1 } { \sqrt { n } } \right)$ なのでサンプルサイズ $n$ が大きければとても良い感じになる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/GOSS.png&quot; alt=&quot;&quot; /&gt;
&lt;strong&gt;GOSSのアルゴリズム(原論文[1]より引用)&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;efbについて&quot;&gt;EFBについて&lt;/h2&gt;

&lt;p&gt;特徴量が高次元のとき、多くの場合ではそれはスパース性を持っています。つまり殆どの特徴量成分はゼロと考えることができます。よって、特徴量それぞれの成分の多くは互いに排他的、つまり、同時に非ゼロの値を取らないという性質が期待できそうです。&lt;/p&gt;

&lt;p&gt;同時に非ゼロにならないという性質を持っている特徴量成分たちを Bundle としてまとめてあげることで、特徴量の次元削減をするというのがEFBの主要なアイデアです。&lt;/p&gt;

&lt;p&gt;実際には成分同士が完全に排他的であることはないので、$K$ 回までは同時に非ゼロになることを許すという感じで適当な閾値をつくって Bundleを作っていきます。これをやっているのが、原論文 [1] のAlgorithm 3です。ただ Algorithm 3通りにやると計算量が $O(\text{特徴量数}^2)$ となってしまうので、Bundleを作るのではなく、非ゼロ成分の数でソートするみたいです。非ゼロ成分の個数が大きくなるほど、同時に非ゼロを取る確率もあがるからというイメージですね。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/greedybundling.png&quot; alt=&quot;&quot; /&gt;
&lt;strong&gt;Greedy Bundlingのアルゴリズム(原論文[1]より引用)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;そうやって作った Bundleを使って、特徴量を次元削減します。あるBundleを1次元のの特徴量にまとめるときに重要な条件は、まとめた特徴量から元の特徴量が復元できるというものです。例えば特徴量$A$ は $[0,10)$ をとり、特徴量 $B$ は$[0,20)$ を取るとします。 $A$ と $B$ をまとめるときに次のような操作をします。 まず、$B$ に 10 だけ足して (offset と原論文では呼んでいます)、範囲を $[10,30)$ にしてから、$[0, 30]$ の範囲で $A$ と $B$ をマージするという方法です。これを具体的に行っているのが Algorithm 4です。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/mef.png&quot; alt=&quot;&quot; /&gt;
&lt;strong&gt;Merge Exclusive Features(原論文[1]より引用)&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;参考文献&quot;&gt;参考文献&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;[1] &lt;a href=&quot;https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree&quot;&gt;LightGBM: A Highly Efficient Gradient Boosting Decision Tree&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="machine-learning" /><summary type="html"></summary></entry><entry><title type="html">Gradirnt Boosting Decision Treeの勉強をした。</title><link href="http://localhost:4000/2019/03/31/gdbt.html" rel="alternate" type="text/html" title="Gradirnt Boosting Decision Treeの勉強をした。" /><published>2019-03-31T00:00:00+09:00</published><updated>2019-03-31T00:00:00+09:00</updated><id>http://localhost:4000/2019/03/31/gdbt</id><content type="html" xml:base="http://localhost:4000/2019/03/31/gdbt.html">&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#動機&quot; id=&quot;markdown-toc-動機&quot;&gt;動機&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#決定木とは&quot; id=&quot;markdown-toc-決定木とは&quot;&gt;決定木とは&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#ブースティング木&quot; id=&quot;markdown-toc-ブースティング木&quot;&gt;ブースティング木&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#最急降下法&quot; id=&quot;markdown-toc-最急降下法&quot;&gt;最急降下法&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#勾配ブースティングとは&quot; id=&quot;markdown-toc-勾配ブースティングとは&quot;&gt;勾配ブースティングとは&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#勾配ブースティング決定木&quot; id=&quot;markdown-toc-勾配ブースティング決定木&quot;&gt;勾配ブースティング決定木&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#参考文献&quot; id=&quot;markdown-toc-参考文献&quot;&gt;参考文献&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;動機&quot;&gt;動機&lt;/h1&gt;

&lt;p&gt;Kaggleなどで話題となっているLightGBMなどのことを知るためにまず、勾配ブースティング決定木の勉強をした。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\DeclareMathOperator{\argmin}{arg\,min}&lt;/script&gt;

&lt;h1 id=&quot;決定木とは&quot;&gt;決定木とは&lt;/h1&gt;

&lt;p&gt;決定木では特徴量 $x$ を元に排反な $J$ 個の分割領域 $\{R_j\}_{j=1}^J$ を構成し、&lt;/p&gt;

&lt;p&gt;$x \in R_j$ のとき、予測値 $f(x)=\gamma_j$ を返す。&lt;/p&gt;

&lt;p&gt;これをまとめて表現すると、$\Theta := \{R_j, \gamma_j \}_{j=1}^J$ として、&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x) = T(x; ) := \sum_{j=1}^J \gamma_j I(x\in R_j)&lt;/script&gt;

&lt;p&gt;とかける。&lt;/p&gt;

&lt;h1 id=&quot;ブースティング木&quot;&gt;ブースティング木&lt;/h1&gt;

&lt;p&gt;ブースティング木とは決定木をたくさん用意した予測モデルです。つまり&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_M(x) = \sum_{m=1}^M T(x;\Theta_m)&lt;/script&gt;

&lt;p&gt;で予測するようなモデルです。&lt;a href=&quot;https://maea2.github.io/adaboost&quot;&gt;Adaboostの記事&lt;/a&gt; でやったように $f_M$ を逐次最適化してみましょう。&lt;/p&gt;

&lt;p&gt;つまり、各 $\hat{\Theta}_m$ を推定するときに&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\Theta}_m = \underset{\Theta_m}{\argmin} \sum_{i=1}^N L(y_i, f_{m-1}(x )+ T(x;\Theta_m))&lt;/script&gt;

&lt;p&gt;で推定してやろうということです。&lt;/p&gt;

&lt;h1 id=&quot;最急降下法&quot;&gt;最急降下法&lt;/h1&gt;

&lt;p&gt;いま、関数　$f$ を使って予測したときの 損失関数の　$x$　についての条件付き期待値&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Phi(x, f) = \mathbb{E}_{x,y} \left[L(y, f(x))| x\right]&lt;/script&gt;

&lt;p&gt;がわかっているとします。&lt;/p&gt;

&lt;p&gt;\Phi(f) を最小にするような予測関数 $f^\ast(x):=\argmin_f \Phi(f)$ がいま得たいものです。&lt;/p&gt;

&lt;p&gt;これを、&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_M(x)=\sum_{m=1}^M f_m(x)&lt;/script&gt;

&lt;p&gt;の形で得ることを考えます。$f_1, f_2, f_3$ と少しづつ $f_i$ を増やして近似していくというイメージです。&lt;/p&gt;

&lt;p&gt;$f_i$ 一つ一つが弱学習器だと思ってください。&lt;/p&gt;

&lt;p&gt;いま、$f_1,\ldots,f_{m-1}$ まで得られているとします。&lt;/p&gt;

&lt;p&gt;いま、最急降下法を使って $f_m$ を計算することを考えます。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;g_m(x) = \left.\frac{\partial \Phi(x^\prime, f_{m-1})}{\partial f(x^\prime)}\right|_{x^\prime=x}&lt;/script&gt;

&lt;p&gt;と置くと、最急降下法によってもとまる $f_m$ は&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_m(x) = f_{m-1}(x) - \rho_m g_m(x)&lt;/script&gt;

&lt;p&gt;となります。$\rho_m$ は $\Phi(x, f_m)$ が最小となるようにとります。&lt;/p&gt;

&lt;h1 id=&quot;勾配ブースティングとは&quot;&gt;勾配ブースティングとは&lt;/h1&gt;

&lt;p&gt;実際は $(x,y)$ の分布は未知であり、有限のサンプルデータ $\{(x_i,y_i)\}$ しか持っていません。&lt;/p&gt;

&lt;p&gt;なので、$g_m(x)$ の値は訓練データ点のところしかわかりません。よって、$\hat{\Theta}_m$ を推定するような問題を考えるとき、この方法は直接は使えません。&lt;/p&gt;

&lt;p&gt;次善の策を考えます。&lt;/p&gt;

&lt;p&gt;つまり有限個の勾配の値 $\{g_m(x_i)\}_{i=1}^N$ と $\{T(x_i;\Theta)\}$ が訓練データ点においてだけでも近くなるように&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tilde{\Theta}_m :=\underset{\Theta}{\argmin}\sum_{i=1}^N (-g_m(x_i)-T(x_i;\Theta))^2&lt;/script&gt;

&lt;p&gt;で定めるという策です。&lt;/p&gt;

&lt;h2 id=&quot;勾配ブースティング決定木&quot;&gt;勾配ブースティング決定木&lt;/h2&gt;

&lt;p&gt;以上を踏まえて勾配ブースティング決定木の最適化アルゴリズムは次のようになります。&lt;/p&gt;

&lt;p&gt;(b)の部分が勾配情報との近くなるようにしている部分です。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/gbdt.png&quot; alt=&quot;&quot; /&gt;
&lt;strong&gt;勾配ブースティング決定木のアルゴリズム (カステラ本のp361より引用)&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;参考文献&quot;&gt;参考文献&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://statweb.stanford.edu/~jhf/ftp/trebst.pdf&quot;&gt;Greedy function approximation a gradient boosting machine&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://web.stanford.edu/~hastie/ElemStatLearn/&quot;&gt;The Elements of
Statistical Learning&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;/p&gt;</content><author><name></name></author><category term="machine-learning" /><category term="math" /><summary type="html"></summary></entry><entry><title type="html">Adaboostは指数損失を最小化している。</title><link href="http://localhost:4000/2019/03/30/adaboost.html" rel="alternate" type="text/html" title="Adaboostは指数損失を最小化している。" /><published>2019-03-30T00:00:00+09:00</published><updated>2019-03-30T00:00:00+09:00</updated><id>http://localhost:4000/2019/03/30/adaboost</id><content type="html" xml:base="http://localhost:4000/2019/03/30/adaboost.html">&lt;h1 id=&quot;adaboostとは&quot;&gt;Adaboostとは&lt;/h1&gt;

&lt;p&gt;Adaboostは単純な分類器(弱学習器)をたくさん集めて、分類モデルを学習するときのアルゴリズムの一つです。&lt;/p&gt;

&lt;p&gt;いま、$Y\in\{-1,1\}$ を正解ラベル、$X\in\mathcal{X}$ を特徴量とする2値分類問題を考えます。&lt;/p&gt;

&lt;p&gt;$G_m:\mathcal{X}\to\{-1,1\}$ となる分類器を$M$個(m=1,2,\ldots,M)用意します。&lt;/p&gt;

&lt;p&gt;これらを用いて分類器 $G(x)$ を&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;G(x)=\mathrm{sign}\left(\sum_{m=1}^M \alpha_mG_m(x)\right)&lt;/script&gt;

&lt;p&gt;で作ることを考えます。&lt;/p&gt;

&lt;p&gt;訓練データ ${x_i,y_i}_{i=1}^N\subset \{-1,1\}\times\mathcal{X}$ が得られているとします。&lt;/p&gt;

&lt;p&gt;このとき、$\{G_m\}&lt;em&gt;{m=1}^M, \{\alpha_m\}&lt;/em&gt;{m=1}^M$ を学習するのが目標です。&lt;/p&gt;

&lt;p&gt;Adaboostは次のようなアルゴリズムです。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/adaboost.png&quot; alt=&quot;fig&quot; /&gt;
&lt;strong&gt;Adaboostのアルゴリズム(カステラ本p339より引用)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Adaboostでは各訓練データに対して重み$w_i$を $m$ について逐次更新します。各 $m$ で $w_i$ に従った重み付きのフィッティングを行い $G_m$ を決定します。&lt;/p&gt;

&lt;p&gt;イメージとしては、前回で誤分類したデータに対しては重みを重く、正解したデータに対しては重みは変えないというような感じで $w_i$ を決定しています。&lt;/p&gt;

&lt;h1 id=&quot;alpha_m-の根拠&quot;&gt;$\alpha_m$ の根拠&lt;/h1&gt;

&lt;p&gt;$w_i$ を更新する際に $\exp(\alpha_m\cdot I(y_i\neq G_m(x_i)))$ 倍していますがこれにはどんな根拠があるのでしょうか。実は指数損失の最小化を考えると、自然とこの値が導かれるというのが今日これから書く内容です。&lt;/p&gt;

&lt;h1 id=&quot;指数損失の最小化から-alpha_m-を出す&quot;&gt;指数損失の最小化から $\alpha_m$ を出す&lt;/h1&gt;

&lt;p&gt;指数損失とは&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\exp(-yG(x))&lt;/script&gt;

&lt;p&gt;で定義される損失です。&lt;/p&gt;

&lt;p&gt;いま&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_m(x) := \sum_{i=1}^m \beta_i G_i(x)&lt;/script&gt;

&lt;p&gt;と定めて、各 $m$ に対して、&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(\beta_m, G_m)　:= \mathrm{argmin}_{\beta, G} \sum_{i=1}^N \exp(-y_i(f_{m-1}(x_i)+\beta G(x_i)))&lt;/script&gt;

&lt;p&gt;で逐次的に $(\beta_m, G_m)$ を決定していくことを考えます。&lt;/p&gt;

&lt;p&gt;$w_i^{(m)}:=\exp(-y_if_{m-1}(x_i))$ と置くと、&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(\beta_m, G_m)　:= \mathrm{argmin}_{\beta, G} \sum_{i=1}^N w_i^{(m)}\exp(-y_i\beta G(x_i))&lt;/script&gt;

&lt;p&gt;と書き換える事ができます。$(\beta_m, G_m)$　は指数損失の重み付き和を最小にするように決定しようというわけです。&lt;/p&gt;

&lt;p&gt;ここで指数損失の重み付き和について次のような書き換えを行います。&lt;/p&gt;

&lt;div class=&quot;slide&quot;&gt;

$$
\begin{align}
&amp;amp;\sum_{i=1}^N w_i^{(m)}\exp(-y_i\beta G(x_i))\\
=&amp;amp;\sum_{y_i=G_i(x)} w_i^{(m)}\exp(-y_i\beta G(x_i)) +
\sum_{y_i\neq G_i(x)} w_i^{(m)}\exp(-y_i\beta G(x_i)))\\
=&amp;amp;\sum_{i=1}^N w_i^{(m)}\exp(-y_i\beta G(x_i))(1-I(y_i\neq G_m(x_i))) +
\sum_{y_i\neq G_i(x)} w_i^{(m)}\exp(-y_i\beta G(x_i))I(y_i\neq G_m(x_i))\\
=&amp;amp;(e^{\beta}+e^{-\beta})\sum_{i=1}^N w_i^{(m)}I(y_i\neq G_m(x_i)) + \sum_{i=1}^N w_i^{(m)}e^{-\beta}
\end{align}
$$

&lt;/div&gt;

&lt;p&gt;これより $G_m$は $\sum_{i=1}^N w_i^{(m)}I(y_i\neq G_m(x_i))$ を最小にするように決めれば良いことがわかります。そのように決定した $G_m$ を代入し、それを $\beta$ について最小化するような $\beta$ を求めれば $\beta_m$ も決定します。&lt;/p&gt;

&lt;p&gt;上の式を $\beta$ について偏微分して整理すると&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;e^{2\beta} = \frac{\sum_{i=1}^N w_i^{(m)}(1-I(y_i\neq G_m(x_i)))}{\sum_{i=1}^N w_i^{(m)}I(y_i\neq G_m(x_i))}&lt;/script&gt;

&lt;p&gt;となります。いま重み付き誤差率 $\mathrm{err}_m$ を&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathrm{err}_m = \frac{\sum_{i=1}^N w_i^{(m)}I(y_i\neq G_m(x_i))}{\sum_{i=1}^N w_i^{(m)}}&lt;/script&gt;

&lt;p&gt;で定めると&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
&amp;e^{2\beta} = \frac{1-\mathrm{err}_m}{\mathrm{err}_m}\\
&amp;\therefore \beta_m = \frac{1}{2} \log\left( \frac{1-\mathrm{err}_m}{\mathrm{err}_m}\right)
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;となります。$\alpha = 2\beta_m$ と置けば、Adaboostの $\alpha_m$ が出てきました。&lt;/p&gt;

&lt;h1 id=&quot;参考文献&quot;&gt;参考文献&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://web.stanford.edu/~hastie/ElemStatLearn/&quot;&gt;The Elements of
Statistical Learning 10章&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;/p&gt;</content><author><name></name></author><category term="machine-learning" /><category term="math" /><summary type="html">Adaboostとは</summary></entry><entry><title type="html">主成分分析の気持ち</title><link href="http://localhost:4000/2019/02/02/pca-objective.html" rel="alternate" type="text/html" title="主成分分析の気持ち" /><published>2019-02-02T00:00:00+09:00</published><updated>2019-02-02T00:00:00+09:00</updated><id>http://localhost:4000/2019/02/02/pca-objective</id><content type="html" xml:base="http://localhost:4000/2019/02/02/pca-objective.html">&lt;p&gt;主成分分析が何を解きたいかということを考えると自分のなかで一番しっくりくる説明を書いてみました。&lt;/p&gt;

&lt;div class=&quot;box&quot;&gt;

平均が$\boldsymbol{0}$となる$p$次元のデータ$\{\boldsymbol{x}_{i}\}_{i=1}^N \subset \mathbb{R}^p$が与えられたときに、元のデータをなるべく損なわないような正規直交系(長さが1で互いに直交するようなベクトルの組)$\{\boldsymbol{u}_i\}_{i=1}^d\subset \mathbb{R}^p$ を見つけてくる。
&lt;/div&gt;

&lt;p&gt;$p$次元ベクトルは1次独立なベクトルが$p$個あれば、それらの線型結合によって表現することができるので、ここでは $d &amp;lt; p$ となる状況を考えています。つまり$p$次元のデータを$d$ 個の直交系を使うことにより「圧縮」して表現してやろうというわけです。&lt;/p&gt;

&lt;p&gt;ここで、「元のデータをなるべく損なわない」の定義は何なのかという疑問が生じますが、ここでは次のような定義を採用します。&lt;/p&gt;

&lt;div class=&quot;box&quot;&gt;

$\{\boldsymbol{u}_{i}\}_{i=1}^d$で張られる空間にデータ $\{\boldsymbol{x}_{i}\}_{i=1}^N$ を直交射影したときの2乗距離の平均が最小になるようにとる。

&lt;/div&gt;

&lt;p&gt;「損なわれなさ」に2乗距離を採用することに数学的な必然性はありません。ただ、最小2乗法などを考えるとわかるようにこうすると後の計算が楽になります。&lt;/p&gt;

&lt;p&gt;いま、ベクトル$\boldsymbol{x}\in\mathbb{R}^p$を&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\{\boldsymbol{u}_i\}_{i=1}^d&lt;/script&gt;

&lt;p&gt;で張られる空間に直交射影したベクトルを考えます。&lt;/p&gt;

&lt;p&gt;これは $\boldsymbol{U}\boldsymbol{U}^\top\boldsymbol{x}$ と表されます。&lt;/p&gt;

&lt;p&gt;なぜなら、直交系で張られる空間に対する射影であることから射影ベクトルは&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{i=1}^d (\boldsymbol{u}_{i}^\top \boldsymbol{x}_{i}) \boldsymbol{u}_{i}&lt;/script&gt;

&lt;p&gt;とかけるからです。&lt;/p&gt;

&lt;p&gt;ここで&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol{U} = [\boldsymbol{u}_1, \ldots, \boldsymbol{u}_{d}]\in \mathbb{R}^{p\times d}&lt;/script&gt;

&lt;p&gt;と置いています。&lt;/p&gt;

&lt;p&gt;これより、主成分分析は次のような問題を解くことになります。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
&amp;\text{minimize}\,\,\frac{1}{N}\sum_{i=1}^N \|\boldsymbol{x}_i - \boldsymbol{U}\boldsymbol{U}^\top\boldsymbol{x}_i\|^2\\

&amp; \text{s.t.}\quad \boldsymbol{U}^\top \boldsymbol{U} = \boldsymbol{I}_d
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;よく主成分分析を説明するときに、データの散らばりが最大になるように分散共分散行列の固有値の大きなものから固有ベクトルを取っていけばよいというような説明がなされますが、これは主成分分析の気持ちとはややずれていると思います。2乗距離が最小になるような直交系をみつけてくるというような説明のほうがしっくりきます。&lt;/p&gt;</content><author><name></name></author><category term="math" /><category term="statistics" /><summary type="html">主成分分析が何を解きたいかということを考えると自分のなかで一番しっくりくる説明を書いてみました。</summary></entry><entry><title type="html">論文の読み方について</title><link href="http://localhost:4000/2018/09/10/how-to-read-a-paper.html" rel="alternate" type="text/html" title="論文の読み方について" /><published>2018-09-10T00:00:00+09:00</published><updated>2018-09-10T00:00:00+09:00</updated><id>http://localhost:4000/2018/09/10/how-to-read-a-paper</id><content type="html" xml:base="http://localhost:4000/2018/09/10/how-to-read-a-paper.html">&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#経緯&quot; id=&quot;markdown-toc-経緯&quot;&gt;経緯&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#やり方&quot; id=&quot;markdown-toc-やり方&quot;&gt;やり方&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#the-first-path&quot; id=&quot;markdown-toc-the-first-path&quot;&gt;The first path&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#the-second-path&quot; id=&quot;markdown-toc-the-second-path&quot;&gt;The second path&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#the-third-path&quot; id=&quot;markdown-toc-the-third-path&quot;&gt;The third path&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;経緯&quot;&gt;経緯&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://www.albany.edu/spatial/WebsiteFiles/ResearchAdvices/how-to-read-a-paper.pdf&quot;&gt;How to read a paper&lt;/a&gt;という
論文の読み方についてのガイドが非常に参考になったので、自分なりにまとめてみたいと思います。&lt;/p&gt;

&lt;h1 id=&quot;やり方&quot;&gt;やり方&lt;/h1&gt;

&lt;p&gt;このガイドではThree-pass approachというものを提案しています。論文を視野を変えて3ステップに分けて読むということです。次の3ステップからなります。よくある感じのやり方ですが、各やり方についての説明が具体的なので、すぐに実践できます。&lt;/p&gt;

&lt;h2 id=&quot;the-first-path&quot;&gt;The first path&lt;/h2&gt;

&lt;p&gt;first path では論文を「ざっと」読んで概要を把握するということをします。具体的には次のような手順で行います。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;論文のタイトル、アブストラクト、イントロダクションを注意深く読む。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;章や説のトピックセンテンス(だいたい1行目が多い)を読む。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;数式などをちらっと見て、アルゴリズムなどがどの分野に関わっていそうな論文かを判断する。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;結論を読む。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;参考文献一覧を読む。以前読んだ文献があるかどうかをチェックする。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;これらの手順を行えば、論文に関して疑問に答えられるようになっているはずです。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;この論文はどの分野の論文か。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;他の論文がこの論文とどのような関係があるか。どのような理論が用いられているか。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;この論文の貢献は何か。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;論文は明快に書かれているか。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;明快に書かれているかというのは、これが満たされていないと論文がリジェクトされてしまうので、ちゃんとした論文であればアブストラクトやイントロダクションがその論文のわかりやすい要約になっているはずだということです。&lt;/p&gt;

&lt;p&gt;first path は自分の研究内容とは関係のない論文(だが将来的には関係するかもしれないような論文)を判断するプロセスと言えます。&lt;/p&gt;

&lt;h2 id=&quot;the-second-path&quot;&gt;The second path&lt;/h2&gt;

&lt;p&gt;second path は論文の詳細を把握するプロセスです。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;論文をfirst path のときよりも注意深く読む。但し、定理の証明などの細部は飛ばして読む。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;読んでいる途中で理解できなかったこと・疑問に思ったことをメモしておく。論文該当箇所などに直接書き込んでもいいかも。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;論文の図表を注意深く見ておく。特にグラフはしっかり見る。軸はちゃんと付いているか、実験結果にエラーバーは付いているかなどを確認する。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;論文に関係しそうなまだ読んでいない参考文献をチェックしておく。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;これは自分で論文を書くときなど(あるかわかりませんが)に、参考文献をレビューする際の手がかりにもなるので、しっかりとやっておく必要があります。&lt;/p&gt;

&lt;p&gt;second path　を行うことによって、この論文のメインとなる主張を根拠をつけて要約することができると思います。&lt;/p&gt;

&lt;h2 id=&quot;the-third-path&quot;&gt;The third path&lt;/h2&gt;

&lt;p&gt;third path は論文の完全な理解のために頭の中で論文の結果を再現するプロセスです。&lt;/p&gt;

&lt;p&gt;主に次のようなことを行います。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;定理の結果、アルゴリズムなどを論文のおいた仮定から再現する。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;third path は分野の初心者には非常に労力の要るプロセスであるということが述べられています。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;third pathを通して、論文やその関連研究において暗黙に仮定されている条件や抜けている条件などを見つけることができます。またその分野の潜在的な課題についても見えてくるでしょう。&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry></feed>